<head>
    <script crossorigin="anonymous" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
    
    <!-- Google AdSense Using Machine Learning Code -->
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
        (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-3071098372371409",
            enable_page_level_ads: true
        });
    </script>

    <style>
        .customTempCodeHolderForSocialMedia {
            display: none;
        }

        pre {
            white-space: pre-wrap;
            white-space: -moz-pre-wrap;
            white-space: -pre-wrap;
            white-space: -o-pre-wrap;
            word-wrap: break-word;
        }
    </style>
</head>

<pre>The simplest one is called 'Step function' or 'Threshold function':

<div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-dfRNLCstUg8/XwLI3ouAa-I/AAAAAAAAFHk/gJKjX2soFqIbmDQkgA_TSGlS3h-ToMm2wCK4BGAsYHg/s1097/Threshold.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="561" data-original-width="1097" height="328" src="https://1.bp.blogspot.com/-dfRNLCstUg8/XwLI3ouAa-I/AAAAAAAAFHk/gJKjX2soFqIbmDQkgA_TSGlS3h-ToMm2wCK4BGAsYHg/w640-h328/Threshold.png" width="640" /></a></div>

Second is the 'Rectifier function':

<div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-Zr-V5s-hpEI/XwLI2atAk6I/AAAAAAAAFHY/j0AtyXtJ2FcrDZoQ3hD9Le1SrHgX05UewCK4BGAsYHg/s971/Rectifier.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="553" data-original-width="971" height="364" src="https://1.bp.blogspot.com/-Zr-V5s-hpEI/XwLI2atAk6I/AAAAAAAAFHY/j0AtyXtJ2FcrDZoQ3hD9Le1SrHgX05UewCK4BGAsYHg/w640-h364/Rectifier.png" width="640" /></a></div>

Third is the Sigmoid function. We also see this one in 'logictic regression' algorithm.

<div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-HSWjYjsyVME/XwLI2qwXmcI/AAAAAAAAFHc/9psrdt5UZcIhN8LLPA2euFlblcXYrSZZwCK4BGAsYHg/s1007/Sigmoid.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="547" data-original-width="1007" height="348" src="https://1.bp.blogspot.com/-HSWjYjsyVME/XwLI2qwXmcI/AAAAAAAAFHc/9psrdt5UZcIhN8LLPA2euFlblcXYrSZZwCK4BGAsYHg/w640-h348/Sigmoid.png" width="640" /></a></div>

Fourth is Hyperbolic Tangent.

<div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-ljuAfKdD19A/XwLI19a1qcI/AAAAAAAAFHU/nkZJwjVh5fMuOXH2rmyNncqryKGcUZdhACK4BGAsYHg/s1061/Hyperbolic%2BTangent.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="549" data-original-width="1061" height="332" src="https://1.bp.blogspot.com/-ljuAfKdD19A/XwLI19a1qcI/AAAAAAAAFHU/nkZJwjVh5fMuOXH2rmyNncqryKGcUZdhACK4BGAsYHg/w640-h332/Hyperbolic%2BTangent.png" width="640" /></a></div>

Fifth is Softplus. Softplus function is a smooth version of the Rectifier function.

f(x) = log(1 + exp(x))

<div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-a7DSK7AjQKU/XwLI3K--P6I/AAAAAAAAFHg/Bm8l2WeMkOkUJxDZbsLYuLIVJwg1XG0fACK4BGAsYHg/s531/Softplus.PNG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="449" data-original-width="531" height="542" src="https://1.bp.blogspot.com/-a7DSK7AjQKU/XwLI3K--P6I/AAAAAAAAFHg/Bm8l2WeMkOkUJxDZbsLYuLIVJwg1XG0fACK4BGAsYHg/w640-h542/Softplus.PNG" width="640" /></a></div>

Below is an illustrative image showing how multiple activation functions are used in a neural network. Here, one in hidden layers and one in output layer:

<div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-9RX26LpAYT8/XwLI1Q1VQvI/AAAAAAAAFHQ/oA0OeDhS4R0yP2yDREGw1G-Z1iO6sp4NACK4BGAsYHg/s615/How%2Bthey%2Bfit%2Btogether.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="318" data-original-width="615" height="331" src="https://1.bp.blogspot.com/-9RX26LpAYT8/XwLI1Q1VQvI/AAAAAAAAFHQ/oA0OeDhS4R0yP2yDREGw1G-Z1iO6sp4NACK4BGAsYHg/w640-h331/How%2Bthey%2Bfit%2Btogether.png" width="640" /></a></div>

A research paper proposes that Rectifier function gives a better performing neural network than one using 'Sigmoid' or 'Hyperbolic Tangent'.

<a href="https://drive.google.com/file/d/1OEOxeOMh7fG0eirbtt3ZcKr-Ijk4CzLT/view?usp=sharing" target="_blank">Deep Sparse Rectifier Neural Networks, Xavier Glorot, 2011</a></pre>