<head>
    <script crossorigin="anonymous" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
  
    <!-- Google AdSense Using Machine Learning Code -->
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
        (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-3071098372371409",
            enable_page_level_ads: true
        });
    </script>
  
    <script>
        $(document).ready(function () {
            $.ajax({
                url: "https://raw.githubusercontent.com/ashishjain1547/pubLessonsInTechnology/main/links_to_tech_clubs.json", 
                success: function (result) {
                    let grouplink = JSON.parse(result)['Beta Tech Club'];
                    $("#customWhatsAppGroupLinkWrapper").html(
                        `
                        <h2 class="custom_link_h2"><a href="${grouplink}" target="_blank"> 
                            <span>Join us on:</span>
                            <span class="customLink"><i class="fa fa-whatsapp"></i> Whatsapp </span>
                            </a>
                        </h2>
                        `    
                    );
                }
            });
        });
    </script>
  
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  
    <style>
        pre {
            white-space: pre-wrap;
            white-space: -moz-pre-wrap;
            white-space: -pre-wrap;
            white-space: -o-pre-wrap;
            word-wrap: break-word;
        }
  
        .customLink {
            background-color: #4CAF50;
            border: none;
            color: white !important;
            padding: 8px 13px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 14px;
            margin: 4px 2px;
            cursor: pointer;
        }
  
        .customLink:hover {
            text-decoration: none;
        }
  
        div.code-block-decoration.footer {
            display: none;
        }
  
        button.export-sheets-button-wrapper {
            display: none;
        }
    </style>
  
    <style>
        .custom_link_h2 a {
            color: black;
            text-decoration: none;
            text-align: center;
        }
  
        .custom_link_h2 a:hover {
            color: black;
        }
  
        .custom_link_h2 a:active {
            color: black;
        }
  
        .custom_link_h2 span {
            translate: 0px -5px;
            display: inline-block;
        }
  
        .custom_link_h2 img {
            width: 100px;
            padding: 0px;
            border: none;
            box-shadow: none;
        }
    </style>
    <style>
      .customul {
        list-style: none;
      }
  
      [aria-hidden='true'] {
        display: none;
      }

      i.ib {
        color: blue;
      }

      i.ig {
        color: green;
      }
    </style>
  
</head>

<div id="customWhatsAppGroupLinkWrapper"></div>

View All Articles on Large Language Models: <a class="customLink" href="http://survival8.blogspot.com/p/index-of-lessons-in-technology.html#customLargeLanguageModels" target="_blank">Lessons in Technology</a>

<div class="separator" style="clear: both;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-WcaxcOwYAXMP1fIrkD7GamPN9WJ2tufgOZE5VLw3mscXOvSE0tuEsFldVrjRgECdyUuT9dUUDAwuHvIjditjmMupcYx5KhVqrmXIfMFFULvOE8UIWYZNRF4JUyTeh2pM7fhrMVysIMNwBlsBQF6qVidI7v6-g03dXZlbtN9x8GNpn1FmsyrNEPV3_C0P/s1200/cover.png" style="display: block; padding: 1em 0; text-align: center; "><img alt="" border="0" width="600" data-original-height="630" data-original-width="1200" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-WcaxcOwYAXMP1fIrkD7GamPN9WJ2tufgOZE5VLw3mscXOvSE0tuEsFldVrjRgECdyUuT9dUUDAwuHvIjditjmMupcYx5KhVqrmXIfMFFULvOE8UIWYZNRF4JUyTeh2pM7fhrMVysIMNwBlsBQF6qVidI7v6-g03dXZlbtN9x8GNpn1FmsyrNEPV3_C0P/s600/cover.png"/></a></div>

<pre>Step 1: Create an API key for free by logging into <a href="https://ai.google.dev/aistudio" target="_blank">Google AI Studio</a> 

A:

<div class="separator" style="clear: both;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgOdcP4ajW19fztRdHKRf0mapWZg-dg9GUDTL1ABAwIQg3_gr2s8YgPpSMFQ_yvLV9_Tg9Nk2UlSJK7hH0RLt8Ts2IqldUeuSdcduMHI880zMg_GKKcw_Qq325I30px4aII_EqcWxrqewXcHF4Lw4ljeD_vg2jDkVsfVOO8PQpLHrpgE7vg9sXCKPzc3mqk/s1112/a.png" style="display: block; padding: 1em 0; text-align: center; "><img alt="" border="0" width="600" data-original-height="737" data-original-width="1112" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgOdcP4ajW19fztRdHKRf0mapWZg-dg9GUDTL1ABAwIQg3_gr2s8YgPpSMFQ_yvLV9_Tg9Nk2UlSJK7hH0RLt8Ts2IqldUeuSdcduMHI880zMg_GKKcw_Qq325I30px4aII_EqcWxrqewXcHF4Lw4ljeD_vg2jDkVsfVOO8PQpLHrpgE7vg9sXCKPzc3mqk/s600/a.png"/></a></div>

B:

<div class="separator" style="clear: both;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh8ttUgt_J7ARTBs8X3AjSvahIrN0VcfAcMZtP1NuvsfxpZxdA1inHNH1WGWgR63U1v_GbUE2MNZbQirNykTpkjyxLuYdP7uxI1cgN85e6yyUXy2Oo1rPEgLHPZgI6QAPFY3mdDJNfNZHYvT_znJeiDIh5wFW8g8-Eo5prSywAJQtHoUCw25XvVohlvdaY-/s1112/b.png" style="display: block; padding: 1em 0; text-align: center; "><img alt="" border="0" width="600" data-original-height="737" data-original-width="1112" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh8ttUgt_J7ARTBs8X3AjSvahIrN0VcfAcMZtP1NuvsfxpZxdA1inHNH1WGWgR63U1v_GbUE2MNZbQirNykTpkjyxLuYdP7uxI1cgN85e6yyUXy2Oo1rPEgLHPZgI6QAPFY3mdDJNfNZHYvT_znJeiDIh5wFW8g8-Eo5prSywAJQtHoUCw25XvVohlvdaY-/s600/b.png"/></a></div>

C:

<div class="separator" style="clear: both;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNfcKcKxKOIkZ_zvsSXzHvEwFJA91w_Ri9EORMMUgVxwjZU1howujN9x1my4mDk_PZEk22YN_jb9heLp5ESRe9MrwpHbfYJ9Xzin15gqLHHcwjC0XSCSTf6pVEA4AQECKfxvfT-McR6reh1qTKgCmQBc7dy_Ufe43MhDUzR4poD6v2Fuwc5mW1pCT_yN1X/s1112/c.png" style="display: block; padding: 1em 0; text-align: center; "><img alt="" border="0" width="600" data-original-height="737" data-original-width="1112" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNfcKcKxKOIkZ_zvsSXzHvEwFJA91w_Ri9EORMMUgVxwjZU1howujN9x1my4mDk_PZEk22YN_jb9heLp5ESRe9MrwpHbfYJ9Xzin15gqLHHcwjC0XSCSTf6pVEA4AQECKfxvfT-McR6reh1qTKgCmQBc7dy_Ufe43MhDUzR4poD6v2Fuwc5mW1pCT_yN1X/s600/c.png"/></a></div>

D:

<div class="separator" style="clear: both;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjRMEV7WP2dLj10sO8RX5T8ek-PiaSPp3HicUyWLq5md7ShuGo_McXXa2haNkl0qJpfdoqEDZIdajgEnqZnic8xDGRF0jET7V02SKdI82Eu72i7C2FFY91pJJQLiTZ67jsynKuxZyTDDtYelUTg1YAcPRQ6XN21aHyH1djxDVERiiMad5PGYHXlzoTIA9vB/s1341/d.png" style="display: block; padding: 1em 0; text-align: center; "><img alt="" border="0" width="600" data-original-height="574" data-original-width="1341" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjRMEV7WP2dLj10sO8RX5T8ek-PiaSPp3HicUyWLq5md7ShuGo_McXXa2haNkl0qJpfdoqEDZIdajgEnqZnic8xDGRF0jET7V02SKdI82Eu72i7C2FFY91pJJQLiTZ67jsynKuxZyTDDtYelUTg1YAcPRQ6XN21aHyH1djxDVERiiMad5PGYHXlzoTIA9vB/s600/d.png"/></a></div>

E: 

<div class="separator" style="clear: both;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfee5q8kgT9rS0ca3Y8sd7gUb4AKXx0923YxLNcHGBykmbhsuDUjGtU8wV5ZJNuLwOo3z9aQ-26fl1sMmT3KgsyeS7IBZQUeuLTNZCOA-fYGdIA55vBeUIu3dPXOyMd7fJwPdKrF5Y9mCN6IFnDM9LvwLQYvBnkVOkQ5mIr-mrN_TFPoW7GRFRyhF27WWk/s1361/e.png" style="display: block; padding: 1em 0; text-align: center; "><img alt="" border="0" width="600" data-original-height="729" data-original-width="1361" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfee5q8kgT9rS0ca3Y8sd7gUb4AKXx0923YxLNcHGBykmbhsuDUjGtU8wV5ZJNuLwOo3z9aQ-26fl1sMmT3KgsyeS7IBZQUeuLTNZCOA-fYGdIA55vBeUIu3dPXOyMd7fJwPdKrF5Y9mCN6IFnDM9LvwLQYvBnkVOkQ5mIr-mrN_TFPoW7GRFRyhF27WWk/s600/e.png"/></a></div>

F: Your free API key is created. Copy it and save it somewhere.

<div class="separator" style="clear: both;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiV0TlUpVTXKcjIGESx4Fw-VnYjCJieV4hKwWBzHlyR8o3V-NkXYUS8G-Z-Ht1K4xixdMxBzBmWLc9D5DM2nCm3iut58Bxpx7TkL0w0U2bNpjuZB6Ec8_LgG8iYdjHh_tEM93SVJdJXdKGOG2BPhJSJPxVIwzLhyEws_m7w4zM1-5WDmVmAwjvuTerVgj-I/s1370/f%20-%20your%20api%20key%20is%20created%20-%20copy%20it%20and%20save%20it%20somewhere.png" style="display: block; padding: 1em 0; text-align: center; "><img alt="" border="0" width="600" data-original-height="730" data-original-width="1370" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiV0TlUpVTXKcjIGESx4Fw-VnYjCJieV4hKwWBzHlyR8o3V-NkXYUS8G-Z-Ht1K4xixdMxBzBmWLc9D5DM2nCm3iut58Bxpx7TkL0w0U2bNpjuZB6Ec8_LgG8iYdjHh_tEM93SVJdJXdKGOG2BPhJSJPxVIwzLhyEws_m7w4zM1-5WDmVmAwjvuTerVgj-I/s600/f%20-%20your%20api%20key%20is%20created%20-%20copy%20it%20and%20save%20it%20somewhere.png"/></a></div>

<h2>Trying a couple of things...</h2>


<i class="ib">
import google.generativeai as genai

API_KEY = 'A...o'

genai.configure(api_key=API_KEY)

model = genai.GenerativeModel()
response = model.generate_content('Teach me about how an LLM works')

print(response.text)
</i>

<i class="ig">
**Understanding Large Language Models (LLMs)**

**Introduction:**

LLMs are advanced machine learning models trained on vast amounts of text data. They can generate human-like text, translate languages, write different types of content, and perform various other text-related tasks.

**Working Principle:**

LLMs are trained on billions of words of text using a technique called transformer neural networks. These networks process sequential data and learn the relationships between words and phrases within the text.

**Training Process:**

1. **Massive Data Collection:** LLMs are trained on enormous datasets of text from various sources, such as books, articles, news, and social media posts.
2. **Tokenization:** The text is broken down into individual words and phrases called "tokens."
3. **Encoding:** Tokens are converted into numerical representations using embedding techniques.
4. **Transformer Architecture:** The transformer neural network processes the encoded tokens, identifying patterns and learning relationships within the text.
5. **Parameter Optimization:** The model adjusts its internal parameters (weights and biases) to minimize a loss function, which measures how well it predicts the next words in the text.
6. **Fine-tuning:** After general training, the LLM can be fine-tuned for specific tasks, such as language translation or content generation.

**Capabilities:**

* **Text Generation:** LLMs can create original, fluent, and grammatically correct text in response to a given prompt.
* **Language Translation:** They can translate text from one language to another with high accuracy.
* **Question Answering:** LLMs can extract information from text and answer questions related to the content.
* **Summarization:** They can condense large amounts of text into concise and informative summaries.
* **Content Creation:** LLMs can generate various types of content, including articles, stories, poems, and website copy.

**Applications:**

* **Natural Language Processing (NLP):** Sentiment analysis, text classification, chatbots
* **Content Generation:** Creative writing, marketing materials, news articles
* **Education:** Language learning, essay writing assistance
* **Research:** Literature analysis, data extraction
* **Customer Service:** Automated response systems, chat support

**Limitations:**

* **Bias:** LLMs can exhibit biases present in their training data.
* **Factual Errors:** They are not immune to factual errors in the sources they are trained on.
* **Limited Contextual Understanding:** They may struggle to understand the full context of complex text.
* **Ethics:** The use of LLMs raises ethical concerns about authorship, misinformation, and deepfakes.</i>

<h3>Listing all models</h3>

<i class="ib">
import pprint
for model in genai.list_models():
    pprint.pprint(model)    
</i>

<i class="ig">
Model(name='models/chat-bison-001',
    base_model_id='',
    version='001',
    display_name='PaLM 2 Chat (Legacy)',
    description='A legacy text-only model optimized for chat conversations',
    input_token_limit=4096,
    output_token_limit=1024,
    supported_generation_methods=['generateMessage', 'countMessageTokens'],
    temperature=0.25,
    top_p=0.95,
    top_k=40)
Model(name='models/text-bison-001',
    base_model_id='',
    version='001',
    display_name='PaLM 2 (Legacy)',
    description='A legacy model that understands text and generates text as an output',
    input_token_limit=8196,
    output_token_limit=1024,
    supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],
    temperature=0.7,
    top_p=0.95,
    top_k=40)

<b>Model(name='models/embedding-gecko-001',
    base_model_id='',
    version='001',
    display_name='Embedding Gecko',
    description='Obtain a distributed representation of a text.',
    input_token_limit=1024,
    output_token_limit=1,
    supported_generation_methods=['embedText', 'countTextTokens'],
    temperature=None,
    top_p=None,
    top_k=None)</b>

Model(name='models/gemini-1.0-pro',
    base_model_id='',
    version='001',
    display_name='Gemini 1.0 Pro',
    description='The best model for scaling across a wide range of tasks',
    input_token_limit=30720,
    output_token_limit=2048,
    supported_generation_methods=['generateContent', 'countTokens'],
    temperature=0.9,
    top_p=1.0,
    top_k=None)
Model(name='models/gemini-1.0-pro-001',
    base_model_id='',
    version='001',
    display_name='Gemini 1.0 Pro 001 (Tuning)',
    description=('The best model for scaling across a wide range of tasks. This is a stable '
                 'model that supports tuning.'),
    input_token_limit=30720,
    output_token_limit=2048,
    supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],
    temperature=0.9,
    top_p=1.0,
    top_k=None)
Model(name='models/gemini-1.0-pro-latest',
    base_model_id='',
    version='001',
    display_name='Gemini 1.0 Pro Latest',
    description=('The best model for scaling across a wide range of tasks. This is the latest '
                 'model.'),
    input_token_limit=30720,
    output_token_limit=2048,
    supported_generation_methods=['generateContent', 'countTokens'],
    temperature=0.9,
    top_p=1.0,
    top_k=None)
Model(name='models/gemini-1.0-pro-vision-latest',
    base_model_id='',
    version='001',
    display_name='Gemini 1.0 Pro Vision',
    description='The best image understanding model to handle a broad range of applications',
    input_token_limit=12288,
    output_token_limit=4096,
    supported_generation_methods=['generateContent', 'countTokens'],
    temperature=0.4,
    top_p=1.0,
    top_k=32)
Model(name='models/gemini-1.5-flash',
    base_model_id='',
    version='001',
    display_name='Gemini 1.5 Flash',
    description='Fast and versatile multimodal model for scaling across diverse tasks',
    input_token_limit=1048576,
    output_token_limit=8192,
    supported_generation_methods=['generateContent', 'countTokens'],
    temperature=1.0,
    top_p=0.95,
    top_k=64)
Model(name='models/gemini-1.5-flash-001',
    base_model_id='',
    version='001',
    display_name='Gemini 1.5 Flash 001',
    description='Fast and versatile multimodal model for scaling across diverse tasks',
    input_token_limit=1048576,
    output_token_limit=8192,
    supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],
    temperature=1.0,
    top_p=0.95,
    top_k=64)
Model(name='models/gemini-1.5-flash-latest',
    base_model_id='',
    version='001',
    display_name='Gemini 1.5 Flash Latest',
    description='Fast and versatile multimodal model for scaling across diverse tasks',
    input_token_limit=1048576,
    output_token_limit=8192,
    supported_generation_methods=['generateContent', 'countTokens'],
    temperature=1.0,
    top_p=0.95,
    top_k=64)
Model(name='models/gemini-1.5-pro',
    base_model_id='',
    version='001',
    display_name='Gemini 1.5 Pro',
    description='Mid-size multimodal model that supports up to 1 million tokens',
    input_token_limit=2097152,
    output_token_limit=8192,
    supported_generation_methods=['generateContent', 'countTokens'],
    temperature=1.0,
    top_p=0.95,
    top_k=64)
Model(name='models/gemini-1.5-pro-001',
    base_model_id='',
    version='001',
    display_name='Gemini 1.5 Pro 001',
    description='Mid-size multimodal model that supports up to 1 million tokens',
    input_token_limit=2097152,
    output_token_limit=8192,
    supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],
    temperature=1.0,
    top_p=0.95,
    top_k=64)
Model(name='models/gemini-1.5-pro-latest',
    base_model_id='',
    version='001',
    display_name='Gemini 1.5 Pro Latest',
    description='Mid-size multimodal model that supports up to 1 million tokens',
    input_token_limit=2097152,
    output_token_limit=8192,
    supported_generation_methods=['generateContent', 'countTokens'],
    temperature=1.0,
    top_p=0.95,
    top_k=64)
Model(name='models/gemini-pro',
    base_model_id='',
    version='001',
    display_name='Gemini 1.0 Pro',
    description='The best model for scaling across a wide range of tasks',
    input_token_limit=30720,
    output_token_limit=2048,
    supported_generation_methods=['generateContent', 'countTokens'],
    temperature=0.9,
    top_p=1.0,
    top_k=None)
Model(name='models/gemini-pro-vision',
    base_model_id='',
    version='001',
    display_name='Gemini 1.0 Pro Vision',
    description='The best image understanding model to handle a broad range of applications',
    input_token_limit=12288,
    output_token_limit=4096,
    supported_generation_methods=['generateContent', 'countTokens'],
    temperature=0.4,
    top_p=1.0,
    top_k=32)
Model(name='models/embedding-001',
    base_model_id='',
    version='001',
    display_name='Embedding 001',
    description='Obtain a distributed representation of a text.',
    input_token_limit=2048,
    output_token_limit=1,
    supported_generation_methods=['embedContent'],
    temperature=None,
    top_p=None,
    top_k=None)
Model(name='models/text-embedding-004',
    base_model_id='',
    version='004',
    display_name='Text Embedding 004',
    description='Obtain a distributed representation of a text.',
    input_token_limit=2048,
    output_token_limit=1,
    supported_generation_methods=['embedContent'],
    temperature=None,
    top_p=None,
    top_k=None)
Model(name='models/aqa',
    base_model_id='',
    version='001',
    display_name='Model that performs Attributed Question Answering.',
    description=('Model trained to return answers to questions that are grounded in provided '
                 'sources, along with estimating answerable probability.'),
    input_token_limit=7168,
    output_token_limit=1024,
    supported_generation_methods=['generateAnswer'],
    temperature=0.2,
    top_p=1.0,
    top_k=40)
</i>

<h3>Getting Embeddings for Input Text</h3>

<i class="ib">
response = genai.generate_embeddings(model="models/embedding-gecko-001", text='Hello World!')

print(response)
</i>

<i class="ig">{'embedding': [-0.020664843, 0.0005969583, 0.041870195, ..., -0.032485683]}</i>
</pre>

<span style="display: none;">Tags: Technology,Large Language Models,</span>