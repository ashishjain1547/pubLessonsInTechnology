<head>
    <script crossorigin="anonymous" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
    
    <!-- Google AdSense Using Machine Learning Code -->
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
        (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-3071098372371409",
            enable_page_level_ads: true
        });
    </script>
    
    <script>
        $(document).ready(function () {
            $.ajax({
                url: "https://raw.githubusercontent.com/ashishjain1547/pubLessonsInTechnology/main/links_to_tech_clubs.json",
                success: function (result) {
                    let grouplink = JSON.parse(result)['Beta Tech Club'];
                    $("#customWhatsAppGroupLinkWrapper").html(
                        `
                        <h2 class="custom_link_h2"><a href="${grouplink}" target="_blank"> 
                            <span>Join us on:</span>
                            <span class="customLink"><i class="fa fa-whatsapp"></i> Whatsapp </span>
                            </a>
                        </h2>
                        `
                    );
                }
            });
        });
    </script>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    
    <style>
        pre {
            white-space: pre-wrap;
            white-space: -moz-pre-wrap;
            white-space: -pre-wrap;
            white-space: -o-pre-wrap;
            word-wrap: break-word;
        }
    
        .customLink {
            background-color: #4CAF50;
            border: none;
            color: white !important;
            padding: 8px 13px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 14px;
            margin: 4px 2px;
            cursor: pointer;
        }
    
        .customLink:hover {
            text-decoration: none;
        }
    
        div.code-block-decoration.footer {
            display: none;
        }
    
        button.export-sheets-button-wrapper {
            display: none;
        }
    </style>
    
    <style>
        .custom_link_h2 a {
            color: black;
            text-decoration: none;
            text-align: center;
        }
    
        .custom_link_h2 a:hover {
            color: black;
        }
    
        .custom_link_h2 a:active {
            color: black;
        }
    
        .custom_link_h2 span {
            translate: 0px -5px;
            display: inline-block;
        }
    
        .custom_link_h2 img {
            width: 100px;
            padding: 0px;
            border: none;
            box-shadow: none;
        }
    </style>
    <style>
        .customul {
            list-style: none;
        }
    
        [aria-hidden='true'] {
            display: none;
        }
    
        .custom_iframe {
            width: 100%;
            height: 305px;
        }
    
        i.ir { color: red; }
        i.ig { color: green; }
        i.ib { color: blue; }
        i.im { color: magenta; }
        i.ip { color: purple; }
    
        .customTable td {
            padding: 2px;
        }
    
        i.green {
            color: green;
        }
    
        i.red {
            color: red;
        }
    
        i.blue {
            color: blue;
        }
    
        button.flex.gap-1.items-center.select-none.px-4.py-1 {
            display: none;
        }
    
        button.flex.select-none.items-center.gap-1 {
            display: none;
        }

        button.bg-token-bg-primary {
            display: none;
        }
    
        .flex.items-center {
            display: none;
        }
    </style>
</head>

<div id="customWhatsAppGroupLinkWrapper"></div>
<br />
<a class="customLink" href="https://survival8.blogspot.com/p/index-of-lessons-in-technology.html#customArtificialIntelligence" target="_blank">See All Articles on AI</a>
&nbsp;&nbsp;
<a class="customLink" href="https://arxiv.org/pdf/2506.02153" target="_blank">Download Research Paper</a>
<br>

<div class="separator" style="clear: both;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjXSm_ZJRMFbVbYDa1Am6v8d_flrXDYmP5AEpVnilfStuXhBVSNWZXtmN7levqEmSlQhcUN_vtNrRYBQFLBq4l4MtByOsy3NDEzLdOMtXtrE1RugDyjqe1bIi9dOJjsXel7vXJ2P3hVgLhpl9ON_KaadNXe2oLpUghfJ2d5z-i2zP2jSjMAYeE7QeNFWFHO/s512/Gemini_Generated_Image_v4h6llv4h6llv4h6.png" style="display: block; padding: 1em 0; text-align: center; "><img alt="" border="0" width="600" data-original-height="275" data-original-width="512" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjXSm_ZJRMFbVbYDa1Am6v8d_flrXDYmP5AEpVnilfStuXhBVSNWZXtmN7levqEmSlQhcUN_vtNrRYBQFLBq4l4MtByOsy3NDEzLdOMtXtrE1RugDyjqe1bIi9dOJjsXel7vXJ2P3hVgLhpl9ON_KaadNXe2oLpUghfJ2d5z-i2zP2jSjMAYeE7QeNFWFHO/s600/Gemini_Generated_Image_v4h6llv4h6llv4h6.png"/></a></div>

<div class="markdown prose dark:prose-invert w-full break-words light markdown-new-styling">

<h2 data-start="172" data-end="204">üß† <strong data-start="178" data-end="204">Research Paper Summary</strong></h2>
<p data-start="206" data-end="262"><strong data-start="206" data-end="218">Authors:</strong> NVIDIA Research (Peter Belcak et al., 2025)</p>
<p data-start="264" data-end="487"><strong data-start="264" data-end="280">Core Thesis:</strong><br data-start="280" data-end="283">
Small Language Models (SLMs) ‚Äî not Large Language Models (LLMs) ‚Äî are better suited for powering the future of <strong data-start="394" data-end="416">agentic AI systems</strong>, which are AI agents designed to perform repetitive or specific tasks.</p>
<hr data-start="489" data-end="492">
<h3 data-start="494" data-end="511">üöÄ Key Points</h3>
<ol data-start="513" data-end="2275">
<li data-start="513" data-end="759">
<p data-start="516" data-end="759"><strong data-start="516" data-end="569">SLMs are powerful enough for most AI agent tasks.</strong><br data-start="569" data-end="572">
Recent models like <em data-start="594" data-end="613">Phi-3 (Microsoft)</em>, <em data-start="615" data-end="636">Nemotron-H (NVIDIA)</em>, and <em data-start="642" data-end="666">SmolLM2 (Hugging Face)</em> achieve performance comparable to large models while being 10‚Äì30x cheaper and faster to run.</p>
</li>
<li data-start="761" data-end="1019">
<p data-start="764" data-end="1019"><strong data-start="764" data-end="820">Agentic AI doesn‚Äôt need general chatty intelligence.</strong><br data-start="820" data-end="823">
Most AI agents don‚Äôt hold long conversations ‚Äî they perform small, repeatable actions (like summarizing text, calling APIs, writing short code). Hence, a smaller, specialized model fits better.</p>
</li>
<li data-start="1021" data-end="1252">
<p data-start="1024" data-end="1252"><strong data-start="1024" data-end="1066">SLMs are cheaper, faster, and greener.</strong><br data-start="1066" data-end="1069">
Running a 7B model can be up to 30x cheaper than a 70B one. They also consume less energy, which helps with sustainability and edge deployment (running AI on your laptop or phone).</p>
</li>
<li data-start="1254" data-end="1440">
<p data-start="1257" data-end="1440"><strong data-start="1257" data-end="1291">Easier to fine-tune and adapt.</strong><br data-start="1291" data-end="1294">
Small models can be trained or adjusted overnight using a single GPU. This makes it easier to tailor them to specific workflows or regulations.</p>
</li>
<li data-start="1442" data-end="1622">
<p data-start="1445" data-end="1622"><strong data-start="1445" data-end="1484">They promote democratization of AI.</strong><br data-start="1484" data-end="1487">
Since SLMs can run locally, more individuals and smaller organizations can build and deploy AI agents ‚Äî not just big tech companies.</p>
</li>
<li data-start="1624" data-end="1828">
<p data-start="1627" data-end="1828"><strong data-start="1627" data-end="1657">Hybrid systems make sense.</strong><br data-start="1657" data-end="1660">
When deep reasoning or open-ended dialogue is needed, SLMs can work alongside occasional LLM calls ‚Äî a modular mix of ‚Äúsmall for most tasks, large for special ones.‚Äù</p>
</li>
<li data-start="1830" data-end="2106">
<p data-start="1833" data-end="1928"><strong data-start="1833" data-end="1856">Conversion roadmap:</strong><br data-start="1856" data-end="1859">
The paper outlines a step-by-step ‚ÄúLLM-to-SLM conversion‚Äù process:</p>
<ul data-start="1932" data-end="2106">
<li data-start="1932" data-end="1966">
<p data-start="1934" data-end="1966">Collect and anonymize task data.</p>
</li>
<li data-start="1970" data-end="1994">
<p data-start="1972" data-end="1994">Cluster tasks by type.</p>
</li>
<li data-start="1998" data-end="2042">
<p data-start="2000" data-end="2042">Select or fine-tune SLMs for each cluster.</p>
</li>
<li data-start="2046" data-end="2106">
<p data-start="2048" data-end="2106">Replace LLM calls gradually with these specialized models.</p>
</li>
</ul>
</li>
<li data-start="2108" data-end="2275">
<p data-start="2111" data-end="2149"><strong data-start="2111" data-end="2147">Case studies show big potential:</strong></p>
<ul data-start="2153" data-end="2275">
<li data-start="2153" data-end="2205">
<p data-start="2155" data-end="2205"><strong data-start="2155" data-end="2166">MetaGPT</strong>: 60% of tasks could be done by SLMs.</p>
</li>
<li data-start="2209" data-end="2236">
<p data-start="2211" data-end="2236"><strong data-start="2211" data-end="2228">Open Operator</strong>: 40%.</p>
</li>
<li data-start="2240" data-end="2275">
<p data-start="2242" data-end="2275"><strong data-start="2242" data-end="2252">Cradle</strong> (GUI automation): 70%.</p>
</li>
</ul>
</li>
</ol>
<hr data-start="2277" data-end="2280">
<h3 data-start="2282" data-end="2309">‚öôÔ∏è Barriers to Adoption</h3>
<ul data-start="2311" data-end="2544">
<li data-start="2311" data-end="2394">
<p data-start="2313" data-end="2394"><strong data-start="2313" data-end="2341">Existing infrastructure:</strong> Billions already invested in LLM-based cloud APIs.</p>
</li>
<li data-start="2395" data-end="2483">
<p data-start="2397" data-end="2483"><strong data-start="2397" data-end="2409">Mindset:</strong> The industry benchmarks everything using general-purpose LLM standards.</p>
</li>
<li data-start="2484" data-end="2544">
<p data-start="2486" data-end="2544"><strong data-start="2486" data-end="2500">Awareness:</strong> SLMs don‚Äôt get as much marketing attention.</p>
</li>
</ul>
<hr data-start="2546" data-end="2549">
<h3 data-start="2551" data-end="2571">üì¢ Authors‚Äô Call</h3>
<p data-start="2572" data-end="2735">NVIDIA calls for researchers and companies to collaborate on advancing <strong data-start="2643" data-end="2676">SLM-first agent architectures</strong> to make AI more efficient, decentralized, and sustainable.</p>
<hr data-start="2737" data-end="2740">
<h2 data-start="2742" data-end="2776">‚úçÔ∏è Blog Post (Layman‚Äôs Version)</h2>
<h3 data-start="2778" data-end="2845">üí° <em data-start="2785" data-end="2845">Why Small Language Models Might Be the Future of AI Agents</em></h3>
<p data-start="2847" data-end="3272">We‚Äôve all heard the buzz around giant AI models like GPT-4 or Claude 3.5. They can chat, code, write essays, and even reason about complex problems. But here‚Äôs the thing ‚Äî when it comes to <em data-start="3036" data-end="3047">AI agents</em> (those automated assistants that handle specific tasks like booking meetings, writing code, or summarizing reports), you don‚Äôt always need a genius. Sometimes, a focused, efficient worker is better than an overqualified one.</p>
<p data-start="3274" data-end="3453">That‚Äôs the argument NVIDIA researchers are making in their new paper:<br data-start="3343" data-end="3346">
üëâ <strong data-start="3349" data-end="3453">Small Language Models (SLMs) could soon replace Large Language Models (LLMs) in most AI agent tasks.</strong></p>
<hr data-start="3455" data-end="3458">
<h3 data-start="3460" data-end="3481">‚öôÔ∏è What Are SLMs?</h3>
<p data-start="3483" data-end="3667">Think of SLMs as the ‚Äúmini versions‚Äù of ChatGPT ‚Äî trained to handle fewer, more specific tasks, but at lightning speed and low cost. Many can run on your own laptop or even smartphone.</p>
<p data-start="3669" data-end="3906">Models like <strong data-start="3681" data-end="3690">Phi-3</strong>, <strong data-start="3692" data-end="3706">Nemotron-H</strong>, and <strong data-start="3712" data-end="3723">SmolLM2</strong> are proving that being small doesn‚Äôt mean being weak. They perform nearly as well as the big ones on things like reasoning, coding, and tool use ‚Äî all the skills AI agents need most.</p>
<hr data-start="3908" data-end="3911">
<h3 data-start="3913" data-end="3952">üöÄ Why They‚Äôre Better for AI Agents</h3>
<ol data-start="3954" data-end="4697">
<li data-start="3954" data-end="4085">
<p data-start="3957" data-end="4085"><strong data-start="3957" data-end="3979">They‚Äôre efficient:</strong><br data-start="3979" data-end="3982">
Running an SLM can cost <em data-start="4009" data-end="4030">10 to 30 times less</em> than an LLM ‚Äî a huge win for startups and small teams.</p>
</li>
<li data-start="4087" data-end="4252">
<p data-start="4090" data-end="4252"><strong data-start="4090" data-end="4107">They‚Äôre fast:</strong><br data-start="4107" data-end="4110">
SLMs respond quickly enough to run on your local device ‚Äî meaning your AI assistant doesn‚Äôt need to send every request to a faraway server.</p>
</li>
<li data-start="4254" data-end="4380">
<p data-start="4257" data-end="4380"><strong data-start="4257" data-end="4282">They‚Äôre customizable:</strong><br data-start="4282" data-end="4285">
You can train or tweak an SLM overnight to fit your workflow, without a massive GPU cluster.</p>
</li>
<li data-start="4382" data-end="4492">
<p data-start="4385" data-end="4492"><strong data-start="4385" data-end="4405">They‚Äôre greener:</strong><br data-start="4405" data-end="4408">
Smaller models use less electricity ‚Äî better for both your wallet and the planet.</p>
</li>
<li data-start="4494" data-end="4697">
<p data-start="4497" data-end="4697"><strong data-start="4497" data-end="4523">They empower everyone:</strong><br data-start="4523" data-end="4526">
If small models become the norm, AI development won‚Äôt stay locked in the hands of tech giants. Individuals and smaller companies will be able to build their own agents.</p>
</li>
</ol>
<hr data-start="4699" data-end="4702">
<h3 data-start="4704" data-end="4740">üîÑ The Future: Hybrid AI Systems</h3>
<p data-start="4742" data-end="5011">NVIDIA suggests a ‚Äúhybrid‚Äù setup ‚Äî let small models handle 90% of tasks, and call in the big models only when absolutely needed (like for complex reasoning or open conversation).<br data-start="4920" data-end="4923">
It‚Äôs like having a small team of efficient specialists with a senior consultant on call.</p>
<hr data-start="5013" data-end="5016">
<h3 data-start="5018" data-end="5046">üß≠ A Shift That‚Äôs Coming</h3>
<p data-start="5048" data-end="5248">The paper even outlines how companies can gradually switch from LLMs to SLMs ‚Äî by analyzing their AI agent workflows, identifying repetitive tasks, and replacing them with cheaper, specialized models.</p>
<p data-start="5250" data-end="5422">So while the world is chasing ‚Äúbigger and smarter‚Äù AIs, NVIDIA‚Äôs message is simple:<br data-start="5333" data-end="5336">
üí¨ <em data-start="5339" data-end="5422">Smaller, faster, and cheaper may actually be smarter for the future of AI agents.</em></p>

</div>
<span style="opacity: 0;">Tags: Technology,Artificial Intelligence,</span>