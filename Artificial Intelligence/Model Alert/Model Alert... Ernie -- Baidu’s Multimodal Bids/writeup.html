<head>
    <script crossorigin="anonymous" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" src="https://code.jquery.com/jquery-3.2.1.min.js"></script>

    <!-- Google AdSense Using Machine Learning Code -->
    <script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
        (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-3071098372371409",
            enable_page_level_ads: true
        });
    </script>

    <script>
        $(document).ready(function () {
            $.ajax({
                url: "https://raw.githubusercontent.com/ashishjain1547/pubLessonsInTechnology/main/links_to_tech_clubs.json",
                success: function (result) {
                    let grouplink = JSON.parse(result)['Beta Tech Club'];
                    $("#customWhatsAppGroupLinkWrapper").html(
                        `
                        <h2 class="custom_link_h2"><a href="${grouplink}" target="_blank"> 
                            <span>Join us on:</span>
                            <span class="customLink"><i class="fa fa-whatsapp"></i> Whatsapp </span>
                            </a>
                        </h2>
                        `
                    );
                }
            });
        });
    </script>

    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"></link>

    <style>
        pre {
            white-space: pre-wrap;
            white-space: -moz-pre-wrap;
            white-space: -pre-wrap;
            white-space: -o-pre-wrap;
            word-wrap: break-word;
        }

        .customLink {
            background-color: #4CAF50;
            border: none;
            color: white !important;
            padding: 8px 13px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 14px;
            margin: 4px 2px;
            cursor: pointer;
        }

        .customLink:hover {
            text-decoration: none;
        }

        div.code-block-decoration.footer {
            display: none;
        }

        button.export-sheets-button-wrapper {
            display: none;
        }
    </style>

    <style>
        .custom_link_h2 a {
            color: black;
            text-decoration: none;
            text-align: center;
        }

        .custom_link_h2 a:hover {
            color: black;
        }

        .custom_link_h2 a:active {
            color: black;
        }

        .custom_link_h2 span {
            translate: 0px -5px;
            display: inline-block;
        }

        .custom_link_h2 img {
            width: 100px;
            padding: 0px;
            border: none;
            box-shadow: none;
        }
    </style>
    <style>
        .customul {
            list-style: none;
        }

        [aria-hidden='true'] {
            display: none;
        }

        .custom_iframe {
            width: 100%;
            height: 305px;
        }

        i.ib {
            color: blue;
        }

        i.ig {
            color: green;
        }

        .customTable td {
            padding: 2px;
        }
</style>

</head>

<div id="customWhatsAppGroupLinkWrapper"></div>

<a class="customLink" href="https://survival8.blogspot.com/p/index-of-lessons-in-technology.html#customAIModelAlerts" target="_blank">See All on AI Model Releases</a>
<br />
<br />



<div class="separator" style="clear: both;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEix09lThrJ4ZQWO0mSZVOGK0YBM-liOC_47iuiDbYR_WZBKs3SyQA-r4FYeZZWL35dpfzzRS2QGJPGxW2XPvMjNEsGEpn3VRMi1Jkz7iFKSFjAysbJaQbIa9C3HF0dxYbBM374SG4iuecms25uo4ltDbKAcYiTnddcMnym-w8VUbsKjaS-rQZeVhUWE23vj/s1200/unnamed.png" style="display: block; padding: 1em 0; text-align: center; "><img alt="" border="0" width="600" data-original-height="675" data-original-width="1200" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEix09lThrJ4ZQWO0mSZVOGK0YBM-liOC_47iuiDbYR_WZBKs3SyQA-r4FYeZZWL35dpfzzRS2QGJPGxW2XPvMjNEsGEpn3VRMi1Jkz7iFKSFjAysbJaQbIa9C3HF0dxYbBM374SG4iuecms25uo4ltDbKAcYiTnddcMnym-w8VUbsKjaS-rQZeVhUWE23vj/s600/unnamed.png"/></a></div>

<div id="m_-7006761834344322509hs_cos_wrapper_hs_email_body_old21_" style="color:inherit;font-size:inherit;line-height:inherit"><h1 style="margin:0;font-family:Helvetica,Arial,sans-serif;line-height:125%;font-size:32px;font-weight:bold">Baidu’s Multimodal Bids</h1>
<p style="line-height:150%">&nbsp;</p>
<p style="line-height:150%">Baidu debuted two models: a lightweight, open-weights, vision-language model and a giant, proprietary, multimodal model built to take on U.S. competitors.</p>
<p style="line-height:150%">&nbsp;</p>
<p style="line-height:150%"><span style="font-weight:bold">Ernie-4.5-VL-28B-A3B-Thinking:</span> Baidu’s new open-weights <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDX43qgz0W8wLKSR6lZ3nNW1HQQS433ZwvRW6rqHXX9hwdKQVsXP5B6bRZqqW4mrfwW4mBrz1W6hSlzx8ZjtHlW41TVv44K4l31W8pJjh67YJXsVW4FpSRP3HL73vW5RLlkX1HhYmvW1RFS2n8vYsW3W7PsFSj6TVdRGW6j50-r8tDldLW3w5qBz1HLX46W6nLFkV4mz3jVVxklg91_Cjw5W8Z--jP3mW916W7t5YJw6Y5q-9W82WX9J2h6lw9W4KZt7c34-bBXW8_VRQc4b5V-vW6hndSC1qnndjW67wrPZ3yDCbsW80Sy2W2gwm9_VPTQ8P5G_xWbVQ_QQ439FMxdW53ssLk8r-WS2W6JG2K-4C7tR_VX6SmN7RGq44f2jhm2004" rel="noopener" style="color:#237b94" target="_blank" data-saferedirecturl="https://www.google.com/url?q=https://info.deeplearning.ai/e3t/Ctc/LX%2B113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDX43qgz0W8wLKSR6lZ3nNW1HQQS433ZwvRW6rqHXX9hwdKQVsXP5B6bRZqqW4mrfwW4mBrz1W6hSlzx8ZjtHlW41TVv44K4l31W8pJjh67YJXsVW4FpSRP3HL73vW5RLlkX1HhYmvW1RFS2n8vYsW3W7PsFSj6TVdRGW6j50-r8tDldLW3w5qBz1HLX46W6nLFkV4mz3jVVxklg91_Cjw5W8Z--jP3mW916W7t5YJw6Y5q-9W82WX9J2h6lw9W4KZt7c34-bBXW8_VRQc4b5V-vW6hndSC1qnndjW67wrPZ3yDCbsW80Sy2W2gwm9_VPTQ8P5G_xWbVQ_QQ439FMxdW53ssLk8r-WS2W6JG2K-4C7tR_VX6SmN7RGq44f2jhm2004&amp;source=gmail&amp;ust=1765234931495000&amp;usg=AOvVaw3SiaIlIvkf7G5GhHKHSgA-">model</a> is based on the earlier Ernie-4.5-21B-A3B Thinking, a text-only MoE reasoning model, plus a 7 billion-parameter vision encoder to process images.It outperforms comparable and larger models on visual reasoning tasks. It can extract on-screen text and analyze videos across time, and it can call tools to zoom in on image details and search for related images.</p>
<ul style="line-height:150%">
<li aria-level="1"><strong>Input/output:</strong> Text, image, video in (up to 128,000 tokens); text out</li>
<li aria-level="1"><strong>Architecture:</strong> Mixture-of-experts (MoE) transformer (28 billion parameters total, 3 billion active per token), 21 billion-parameter language decoder/encoder.&nbsp;</li>
<li aria-level="1"><span style="font-weight:bold">Training:</span> The authors used vision-language reasoning examples during&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWP3qgz0W7Y8-PT6lZ3mSW8Mf7rb8JzJ6SW27bB1r6LT5gwW1FDhsc1wzxW0W5VNn9246ThJ_W1Xrv8y45XFHlN7b4Z-kks6dgMrgg8Tk_rSkV6l7bh8FRrXkW5m6Dgc6zpw1pN6Hlt3T_jQY7W48t4Mz7dSC1mW8cfTKY6X2t2GW2Z0KZk2NHzPPW4dY4tH8tXLhSN7xLfG2BlF5jW94MtDR709KfyW937jK922YJtSW8st2zt5PkwR7W77Hfsn6hwPyrVyCMg68yP2HjW7WTMJk4jSQGBW2NWYpJ7s9chsW6K-PNr4Cj2_bW59qDLG8tQp1PW7GNJ9l4C41-1N29f99qrymCBf6LQgTx04" rel="noopener" style="color:#237b94" target="_blank" data-saferedirecturl="https://www.google.com/url?q=https://info.deeplearning.ai/e3t/Ctc/LX%2B113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWP3qgz0W7Y8-PT6lZ3mSW8Mf7rb8JzJ6SW27bB1r6LT5gwW1FDhsc1wzxW0W5VNn9246ThJ_W1Xrv8y45XFHlN7b4Z-kks6dgMrgg8Tk_rSkV6l7bh8FRrXkW5m6Dgc6zpw1pN6Hlt3T_jQY7W48t4Mz7dSC1mW8cfTKY6X2t2GW2Z0KZk2NHzPPW4dY4tH8tXLhSN7xLfG2BlF5jW94MtDR709KfyW937jK922YJtSW8st2zt5PkwR7W77Hfsn6hwPyrVyCMg68yP2HjW7WTMJk4jSQGBW2NWYpJ7s9chsW6K-PNr4Cj2_bW59qDLG8tQp1PW7GNJ9l4C41-1N29f99qrymCBf6LQgTx04&amp;source=gmail&amp;ust=1765234931495000&amp;usg=AOvVaw1g-aZDAYDlNJMoyfrykBsB">mid-training</a>, an emerging phase that typically uses mid-size datasets to sharpen distinct skills or impart specific domains prior to fine-tuning.&nbsp;In addition, they fine-tune via reinforcement learning (RL) with multimodal data. Because MoE architectures can become unstable during RL, the team used a combination of <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWv3qgz0W7lCdLW6lZ3lhVD8rCS7QW4NHN7NtXR--T5GhW1422363mDTwQW85D7XH3BDZtVW6WfYp86lvN2yVjCcW-2by6VvW8RY7F116tlwwW55f12p7czdklVk7tNb5fvjPJW6tcDp11Y_XT0W6FzkjF5zHddNN4_wYNH_xMyPW17qNnB8PG2sHW4HBq-v65dCjRN33zQPgVfmSPW8vCHX15trFhSVJgL5_2w7FdqW4zll3J6VtgXCN7hS9R6R7M4ZW5jnWQk2CBbRWW6kSqPC1c7VRRW6smPTJ2Vh9sxW41LSBz2LMCCTW1Dmb1H88dffnf8SkFWW04" rel="noopener" style="color:#237b94" target="_blank" data-saferedirecturl="https://www.google.com/url?q=https://info.deeplearning.ai/e3t/Ctc/LX%2B113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWv3qgz0W7lCdLW6lZ3lhVD8rCS7QW4NHN7NtXR--T5GhW1422363mDTwQW85D7XH3BDZtVW6WfYp86lvN2yVjCcW-2by6VvW8RY7F116tlwwW55f12p7czdklVk7tNb5fvjPJW6tcDp11Y_XT0W6FzkjF5zHddNN4_wYNH_xMyPW17qNnB8PG2sHW4HBq-v65dCjRN33zQPgVfmSPW8vCHX15trFhSVJgL5_2w7FdqW4zll3J6VtgXCN7hS9R6R7M4ZW5jnWQk2CBbRWW6kSqPC1c7VRRW6smPTJ2Vh9sxW41LSBz2LMCCTW1Dmb1H88dffnf8SkFWW04&amp;source=gmail&amp;ust=1765234931495000&amp;usg=AOvVaw14SbUnWw5mn_-vjwgmXw9i">GSPO</a>&nbsp;and <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDVj5nR3bW50kH_H6lZ3pQW2_j8gh2dg6XnW3RHzBH602kC0W6bJQb04_9DBcW6N_94783ZrM6W8SQSdD5f3cVlW66b8xF5rkQ39W1lHGqR7DkxxsW3PB4fZ2LGNqxVcVVfG3M76jlW49_GvV6yjG65W66Hpyk29k3CtW82FYj76n4bgvW2nTzk47BNSJRW1lyPLf8JcPbtW8XlLvD7G2ZGgW2TK2TB1kVfBYVK-1SY8lKDTwVlxvbz5K3D6-W7VfXpk6-T85rN98C3r4htwVlVhyCsv8XPwW5W60-8_t7gyF8kW4ft-Tj91bCdcW6F2Gmb8syh4nW4MprmW402bgBW5mbTDZ89C294N1bksSylQBjnMCG4kz3fVGTW1yhtQ191Xf7SW352lHk1-xHhsW8Wcjz-4rH4cdW34Gk5T2btCl6f5PBD3l04" rel="noopener" style="color:#237b94" target="_blank" data-saferedirecturl="https://www.google.com/url?q=https://info.deeplearning.ai/e3t/Ctc/LX%2B113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDVj5nR3bW50kH_H6lZ3pQW2_j8gh2dg6XnW3RHzBH602kC0W6bJQb04_9DBcW6N_94783ZrM6W8SQSdD5f3cVlW66b8xF5rkQ39W1lHGqR7DkxxsW3PB4fZ2LGNqxVcVVfG3M76jlW49_GvV6yjG65W66Hpyk29k3CtW82FYj76n4bgvW2nTzk47BNSJRW1lyPLf8JcPbtW8XlLvD7G2ZGgW2TK2TB1kVfBYVK-1SY8lKDTwVlxvbz5K3D6-W7VfXpk6-T85rN98C3r4htwVlVhyCsv8XPwW5W60-8_t7gyF8kW4ft-Tj91bCdcW6F2Gmb8syh4nW4MprmW402bgBW5mbTDZ89C294N1bksSylQBjnMCG4kz3fVGTW1yhtQ191Xf7SW352lHk1-xHhsW8Wcjz-4rH4cdW34Gk5T2btCl6f5PBD3l04&amp;source=gmail&amp;ust=1765234931495000&amp;usg=AOvVaw3l1nsX-GRBCXTUmicqZvD1">IcePop</a>&nbsp;to stabilize the fine-tuning.</li>
<li aria-level="1"><strong>Features:</strong> Tool use, reasoning</li>
<li aria-level="1"><span style="font-weight:bold">Performance:</span> Ernie-4.5-VL-28B-A3B-Thinking competes with larger proprietary models on document understanding tasks despite activating only 3 billion parameters, Baidu said. For instance, on ChartQA (chart interpretation), Ernie-4.5-VL-28B-A3B-Thinking reached 87.1 percent accuracy, outperforming Gemini 2.5 Pro (76.3 percent) and GPT-5 set to high reasoning (78.2 percent). On OCRBench (text recognition in images), it achieved 858, ahead of GPT-5 set to high reasoning&nbsp;(810) but trailing Gemini 2.5 Pro (866).</li>
<li aria-level="1"><span style="font-weight:bold">Availability:</span> Weights free for noncommercial and commercial uses under Apache 2.0 license via <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWP3qgz0W7Y8-PT6lZ3kQW3-4Gbh7qW93_W3vWxyV5VxGBJVKfvdf41b9ybW1gS2ZJ2YggX8W1CJ6fb8JhGRDW6Sfvdh6m9XbxW82GMnf8LzB6XMC4Pf4N1ZfTW7QmSxt5FjFtLW8MlF0z7pb9GTW7GCtV27PC1GPW5GrNZC7TszKrW4ZS6JX61sgBYW7Ghn4L8JX6yXN1R0Z0mbTpP9W4kjBzp15DjzyW3h0bXT5jxZbzW197Ltq2yn-hQW2Kqvl89dtZjPW6YbXMr7dQbH8W1RjKb91S6--DW6yRt918Js3nMW4BtQX14qxYbKW3GLQh24kBX-8W8X8nZY8wg8kZN3w0NXPdYZBjf7hwQDK04" rel="noopener" style="color:#237b94" target="_blank" data-saferedirecturl="https://www.google.com/url?q=https://info.deeplearning.ai/e3t/Ctc/LX%2B113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWP3qgz0W7Y8-PT6lZ3kQW3-4Gbh7qW93_W3vWxyV5VxGBJVKfvdf41b9ybW1gS2ZJ2YggX8W1CJ6fb8JhGRDW6Sfvdh6m9XbxW82GMnf8LzB6XMC4Pf4N1ZfTW7QmSxt5FjFtLW8MlF0z7pb9GTW7GCtV27PC1GPW5GrNZC7TszKrW4ZS6JX61sgBYW7Ghn4L8JX6yXN1R0Z0mbTpP9W4kjBzp15DjzyW3h0bXT5jxZbzW197Ltq2yn-hQW2Kqvl89dtZjPW6YbXMr7dQbH8W1RjKb91S6--DW6yRt918Js3nMW4BtQX14qxYbKW3GLQh24kBX-8W8X8nZY8wg8kZN3w0NXPdYZBjf7hwQDK04&amp;source=gmail&amp;ust=1765234931495000&amp;usg=AOvVaw34AAyVi4NzA_3Tbzp_1NYa">HuggingFace</a>. API $0.14/$0.56 per million input/output tokens via <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWP3qgz0W7Y8-PT6lZ3lvW1LSddd92CdHzW2HPcHq6s9YjPW5BQd1g4kmtNWV6PT1N8d_LgRW4_2QNF1gtD91W3GKvK-4yhhm8W61_f0M3JMlRvW5MhQLR5ChcXLVp3l532G4cySW2V49j410yN_qN2_SwBVx3cMzW547TCF93m7qLW2W8ZTY6fcQTmW8PZyX22gVFPgW5V6zSj54w0nHW5MWDV37-CMJvW7dj7LH6fDhVvW3BvB9W8slDwfW6hTg4Z44Fh7MW6fZYfn2CxBcgW86yKCQ14PKC4W8Lz64b78znqmW3R3jbX6r6L4rN1tKRvnYqKn2W9fz-tS4nmwylW4jBbzg7Tmyszf3TSbwT04" rel="noopener" style="color:#237b94" target="_blank" data-saferedirecturl="https://www.google.com/url?q=https://info.deeplearning.ai/e3t/Ctc/LX%2B113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWP3qgz0W7Y8-PT6lZ3lvW1LSddd92CdHzW2HPcHq6s9YjPW5BQd1g4kmtNWV6PT1N8d_LgRW4_2QNF1gtD91W3GKvK-4yhhm8W61_f0M3JMlRvW5MhQLR5ChcXLVp3l532G4cySW2V49j410yN_qN2_SwBVx3cMzW547TCF93m7qLW2W8ZTY6fcQTmW8PZyX22gVFPgW5V6zSj54w0nHW5MWDV37-CMJvW7dj7LH6fDhVvW3BvB9W8slDwfW6hTg4Z44Fh7MW6fZYfn2CxBcgW86yKCQ14PKC4W8Lz64b78znqmW3R3jbX6r6L4rN1tKRvnYqKn2W9fz-tS4nmwylW4jBbzg7Tmyszf3TSbwT04&amp;source=gmail&amp;ust=1765234931495000&amp;usg=AOvVaw3UwLotzebELy2a_hBUAXFw">Baidu Qianfan</a>.</li>
<li aria-level="1"><strong>Undisclosed:</strong> Output size limit, training data, reward models</li>
</ul>
<p style="line-height:150%"><span style="font-weight:bold">Ernie-5.0:</span> Baidu describes&nbsp;Ernie-5.0’s approach as natively multimodal, meaning it was trained on text, images, audio, and video together rather than fusing different media encoders after training or routing inputs to specialized models. It performs comparably to the similarly multimodal Google Gemini 2.5 or OpenAI GPT-5, according to Baidu.</p>
<ul style="line-height:150%">
<li aria-level="1"><strong>Input/output:</strong> Text, image, audio, and video in (up to 128,000 tokens); text, image, audio, video out (up to 64,000 tokens)</li>
<li aria-level="1"><span style="font-weight:bold">Architecture:</span> Mixture-of-experts (MoE) transformer (2.4 trillion&nbsp;parameters total, less than 72 billion active per token)</li>
<li aria-level="1"><strong>Features:</strong> Vision-language-audio understanding, reasoning, agentic planning, tool use</li>
<li aria-level="1"><span style="font-weight:bold">Performance:</span> In Baidu’s tests of multimodal reasoning, document understanding, and visual question-answering, the company reports that Ernie-5.0 matched or exceeded&nbsp;OpenAI GPT-5 set to high reasoning and Google Gemini 2.5 Pro. For instance, on OCRBench (document comprehension), DocVQA (document comprehension), and ChartQA (structured data reasoning), Baidu Ernie-5.0 achieved top scores. On <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWv3qgz0W7lCdLW6lZ3mpW7RC6kv4cR5VRW2jz8tV3j9br-W6wC5ng5-X5r5W2s0MZ24bPTlZW6YM8Bx56fydNW1Z0fRq2cQgBvW6gwWg81cFvwKW6p4nPx5kTlHTW5tMNBF5h1HCQW7-jV1-6J4dKPW3GMm7l7r39PlW2PcHXj8C20QGW232Tyw7k-tPsVh5w5M7Pwh3zW3cnWSS74YqngW2KmhmY1gnPf0W5lvcfH4VxyL2W2QcdyQ83LHXKV2XNWq84wZYKW6X3bbZ3y07ftW1ZWXSN4v89_VW3cPwXq8Pd222N987FMPNqvjyW5ZQhCq6vd8CldhjDN604" rel="noopener" style="color:#237b94" target="_blank" data-saferedirecturl="https://www.google.com/url?q=https://info.deeplearning.ai/e3t/Ctc/LX%2B113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWv3qgz0W7lCdLW6lZ3mpW7RC6kv4cR5VRW2jz8tV3j9br-W6wC5ng5-X5r5W2s0MZ24bPTlZW6YM8Bx56fydNW1Z0fRq2cQgBvW6gwWg81cFvwKW6p4nPx5kTlHTW5tMNBF5h1HCQW7-jV1-6J4dKPW3GMm7l7r39PlW2PcHXj8C20QGW232Tyw7k-tPsVh5w5M7Pwh3zW3cnWSS74YqngW2KmhmY1gnPf0W5lvcfH4VxyL2W2QcdyQ83LHXKV2XNWq84wZYKW6X3bbZ3y07ftW1ZWXSN4v89_VW3cPwXq8Pd222N987FMPNqvjyW5ZQhCq6vd8CldhjDN604&amp;source=gmail&amp;ust=1765234931495000&amp;usg=AOvVaw0r3hBAkiQ0DQ0QXf-4Y758">MM-AU</a>&nbsp;(multimodal audio understanding) and <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDX43qgz0W8wLKSR6lZ3mKVH6kFj5TkBn-W4DJ3PL3hWgwZW38P4tl6g8FGvW1ZYG3Y7p7ZbqW55ps7q1fGj1WW40nqlR40dVWXW32cRdd20VQ5yW4yx1714LsfthN4nRj25LVmzHW8TZP5J2FwWL6W88fqyG7x3khRW74QqMz3gZB_NN1Cjc5CJvSJHW5cYM8n3gHth-W49F5Zl9jKCDmW4fQxzF1_tRG1W2GrZJD5c3Mj6W5Hlc3j3Xf7TzW76SlXY2c78GWW1_NkfP5qhC-DW6dryPQ16mGmlW343Qp7109pm9W76s1bW47Z2fBN4sftkXFbvD5N7BBb19zgBVrW3stk0N3PXvTgW2fqWcT25vDY2W1q7S9t34VKrkf188GNg04" rel="noopener" style="color:#237b94" target="_blank" data-saferedirecturl="https://www.google.com/url?q=https://info.deeplearning.ai/e3t/Ctc/LX%2B113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDX43qgz0W8wLKSR6lZ3mKVH6kFj5TkBn-W4DJ3PL3hWgwZW38P4tl6g8FGvW1ZYG3Y7p7ZbqW55ps7q1fGj1WW40nqlR40dVWXW32cRdd20VQ5yW4yx1714LsfthN4nRj25LVmzHW8TZP5J2FwWL6W88fqyG7x3khRW74QqMz3gZB_NN1Cjc5CJvSJHW5cYM8n3gHth-W49F5Zl9jKCDmW4fQxzF1_tRG1W2GrZJD5c3Mj6W5Hlc3j3Xf7TzW76SlXY2c78GWW1_NkfP5qhC-DW6dryPQ16mGmlW343Qp7109pm9W76s1bW47Z2fBN4sftkXFbvD5N7BBb19zgBVrW3stk0N3PXvTgW2fqWcT25vDY2W1q7S9t34VKrkf188GNg04&amp;source=gmail&amp;ust=1765234931495000&amp;usg=AOvVaw3yI3NVWCQBhLafFn1-4_NA">TUT2017</a>&nbsp;(acoustic scene classification), it demonstrated competitive performance, Baidu said without publishing specific metrics.</li>
<li aria-level="1"><span style="font-weight:bold">Availability:</span> Free <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWb3qgz0W6N1vHY6lZ3mtW3z7nPj2XzncRW7f4XXR1hGKZ9W52kSgf1rnhV9W50CLxr5nVPT_W5kpWjZ3t0DhyW1d47r61phHb6W2cs-1_1lCYcqN46G2JQlMG9LW4xDH9d3MgChkW1Ync5n7M9vcsN8TMW7HJ6SMLV-DJr486G-pbW2ZNky47PvDp6W1VTVhK516PPkW1DNQC56928MlW4fnRWL7pd-gxW12Pnmw8w-Fq6W7__jz65CSx1kW4-SDwX7w8d29W2YtwNd6kb2HtW5R289d8BMcP8W4twDhN7Xmp03f7zWXr204" rel="noopener" style="color:#237b94" target="_blank" data-saferedirecturl="https://www.google.com/url?q=https://info.deeplearning.ai/e3t/Ctc/LX%2B113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWb3qgz0W6N1vHY6lZ3mtW3z7nPj2XzncRW7f4XXR1hGKZ9W52kSgf1rnhV9W50CLxr5nVPT_W5kpWjZ3t0DhyW1d47r61phHb6W2cs-1_1lCYcqN46G2JQlMG9LW4xDH9d3MgChkW1Ync5n7M9vcsN8TMW7HJ6SMLV-DJr486G-pbW2ZNky47PvDp6W1VTVhK516PPkW1DNQC56928MlW4fnRWL7pd-gxW12Pnmw8w-Fq6W7__jz65CSx1kW4-SDwX7w8d29W2YtwNd6kb2HtW5R289d8BMcP8W4twDhN7Xmp03f7zWXr204&amp;source=gmail&amp;ust=1765234931495000&amp;usg=AOvVaw0ByNLGw8_BjAwwKRp2BdHm">web interface</a>, API $0.85/$3.40 per million input/output tokens via <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWP3qgz0W7Y8-PT6lZ3nvW3hxNG62GzLsvW3BD2j92CPyNnW7T32Rp20XKSCW4HNCls2kwSTJW43L4QH6Sq8tnW8NvR6B4K4WLBW7F8R2p4jDDFvW3Z-2mj74knByW1z21sG2jQvb_W5LKNt639g9R-W280Nvv2wCjwzW6vpDWR7HmtBZW9dwbsk7M-5x2W8PxlMF3S8fqfW1Ql_tb262_-XW1fqYwQ46hD29W22KGwM4Qx4tpW5Wlymj1scSSMW8m6ykG6ZqHQ7TyTcg4KJD2NW1bvqpD252BHHW631X0k8dzY4pW9cvLWN7jnm3sW4sNHhg7wDlQqW2gt7yt96w4dJVsB41x41q2FCf8xT1Mx04" rel="noopener" style="color:#237b94" target="_blank" data-saferedirecturl="https://www.google.com/url?q=https://info.deeplearning.ai/e3t/Ctc/LX%2B113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWP3qgz0W7Y8-PT6lZ3nvW3hxNG62GzLsvW3BD2j92CPyNnW7T32Rp20XKSCW4HNCls2kwSTJW43L4QH6Sq8tnW8NvR6B4K4WLBW7F8R2p4jDDFvW3Z-2mj74knByW1z21sG2jQvb_W5LKNt639g9R-W280Nvv2wCjwzW6vpDWR7HmtBZW9dwbsk7M-5x2W8PxlMF3S8fqfW1Ql_tb262_-XW1fqYwQ46hD29W22KGwM4Qx4tpW5Wlymj1scSSMW8m6ykG6ZqHQ7TyTcg4KJD2NW1bvqpD252BHHW631X0k8dzY4pW9cvLWN7jnm3sW4sNHhg7wDlQqW2gt7yt96w4dJVsB41x41q2FCf8xT1Mx04&amp;source=gmail&amp;ust=1765234931495000&amp;usg=AOvVaw3FcaRAzfS3NhQNvdAEJ2f6">Baidu Qianfan</a></li>
<li aria-level="1"><strong>Undisclosed:</strong> Training data, training methods</li>
</ul>
<p style="line-height:150%"><span style="font-weight:bold">Yes, but:</span> Shortly after Ernie-5.0's launch, a developer <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWP3qgz0W7Y8-PT6lZ3p8W4bRT_d1JGB63W4d_Glr2-r4VhW1jSQnk2c06BTW5byXt45nv-2DN6Cj0bbm0LszN7-nFwc8Ydn0W3kpxyp5WYN04W2T-37J3ps1DsW4zq-7c2rQ5WwW708zHH2PqYrnW8D9cPX2h0vz5VCPmvV3r8zXBW6p3YcT5xzLkLV6jXkj5mb_W-N5C6QKl-lJm8W4_03HJ8hdMlZW5jz3n348JM4kVchBYs8dTm8TW5JLJDf2R4wlgW2tDbQy9fxVZfVbgfnt6R7VFjW34pFcz1-x8QtW67BhdY4rTLf8W3nWPYT5n7S62W4TyjCL7t0SBhW7dBDhR5ShBWdf4SbGQ204" rel="noopener" style="color:#237b94" target="_blank" data-saferedirecturl="https://www.google.com/url?q=https://info.deeplearning.ai/e3t/Ctc/LX%2B113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWP3qgz0W7Y8-PT6lZ3p8W4bRT_d1JGB63W4d_Glr2-r4VhW1jSQnk2c06BTW5byXt45nv-2DN6Cj0bbm0LszN7-nFwc8Ydn0W3kpxyp5WYN04W2T-37J3ps1DsW4zq-7c2rQ5WwW708zHH2PqYrnW8D9cPX2h0vz5VCPmvV3r8zXBW6p3YcT5xzLkLV6jXkj5mb_W-N5C6QKl-lJm8W4_03HJ8hdMlZW5jz3n348JM4kVchBYs8dTm8TW5JLJDf2R4wlgW2tDbQy9fxVZfVbgfnt6R7VFjW34pFcz1-x8QtW67BhdY4rTLf8W3nWPYT5n7S62W4TyjCL7t0SBhW7dBDhR5ShBWdf4SbGQ204&amp;source=gmail&amp;ust=1765234931495000&amp;usg=AOvVaw0bfi1xLTwJaWjXBdzH7oa1">reported</a> that the model repeatedly called tools even after instruction&nbsp;not to. Baidu <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWP3qgz0W7Y8-PT6lZ3lvW7_WhbQ4YRkSgW2HJZGr3cpPR3W1fpT8851khS5N3wF37NV2-9tW7_Mysc3ZQsPBW3BCsBj4CxgrqW7zKZjP40THQsW4Yfy7w8ZBfGyW8HNRyc2CMcZ2VPW3Tx7vY-P7W2KH42k2-3CPbW2mlvVk1zps87W8SbpsQ4LFcSrW2yJfLB3MH6jmW6ZgF8Y89zHltN1HtQCJz46YxN7Q5lwggBCqMW7-KMt04JqBxLW92Hpzd1x2MFxW92ZT738TKb_pN6FfLWw2sRY1W3FRpYS8KNWSqW1HR7CX7WHmBWV_nFwy5Kh79ZW1gQ-Kd2kmQv2W37SCJm7Z7B2ddr2b2d04" rel="noopener" style="color:#237b94" target="_blank" data-saferedirecturl="https://www.google.com/url?q=https://info.deeplearning.ai/e3t/Ctc/LX%2B113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWP3qgz0W7Y8-PT6lZ3lvW7_WhbQ4YRkSgW2HJZGr3cpPR3W1fpT8851khS5N3wF37NV2-9tW7_Mysc3ZQsPBW3BCsBj4CxgrqW7zKZjP40THQsW4Yfy7w8ZBfGyW8HNRyc2CMcZ2VPW3Tx7vY-P7W2KH42k2-3CPbW2mlvVk1zps87W8SbpsQ4LFcSrW2yJfLB3MH6jmW6ZgF8Y89zHltN1HtQCJz46YxN7Q5lwggBCqMW7-KMt04JqBxLW92Hpzd1x2MFxW92ZT738TKb_pN6FfLWw2sRY1W3FRpYS8KNWSqW1HR7CX7WHmBWV_nFwy5Kh79ZW1gQ-Kd2kmQv2W37SCJm7Z7B2ddr2b2d04&amp;source=gmail&amp;ust=1765234931495000&amp;usg=AOvVaw1CJD0bvGLidlAAUvLoXMxN">acknowledged</a> the issue and said it was fixing it.</p>
<p style="line-height:150%">&nbsp;</p>
<p style="line-height:150%"><span style="font-weight:bold">Why it matters:</span> Ernie-4.5-VL-28B-A3B-Thinking offers top visual reasoning at the fraction of the cost of competing models, and more flexibility for fine-tuning and other commercial customizations. However, the long-awaited Ernie 5.0 appears to fall short of <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDX43qgz0W8wLKSR6lZ3pNW1w0cy-9hJcDyW5phh8F7LBJTvW6WMvCW5QCY2xW78cDXC5p1TnHW9l6BvJ1mCG81V9dHsy7YD38kN48mflnyFPRRW97lbQV83p-gbW2wP2b34x5vk0W2vXS4B6f3L6pW9ffqH17071M0N6nZjx1KxYrjW3nCl2N6Nq8pJW5dCtP-6wrRw4W2q-ktp5SP_t9N3bFHkNxGp7gW9gznDf729QB8W526fbt1NwHbwW1HZ_1l6JJ2vnW3KNjQB8CQTsxN1Zk5SYj6JnwW2sq8ZT8pSCpbW7x8HWT6tHq95W1RCmGv50R_dMW4zC2kF8C8zZtVP6HzT2S2Bl1W6t299h13JG_WW8d63G69jty7Wf8p5PJ204" rel="noopener" style="color:#237b94" target="_blank" data-saferedirecturl="https://www.google.com/url?q=https://info.deeplearning.ai/e3t/Ctc/LX%2B113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDX43qgz0W8wLKSR6lZ3pNW1w0cy-9hJcDyW5phh8F7LBJTvW6WMvCW5QCY2xW78cDXC5p1TnHW9l6BvJ1mCG81V9dHsy7YD38kN48mflnyFPRRW97lbQV83p-gbW2wP2b34x5vk0W2vXS4B6f3L6pW9ffqH17071M0N6nZjx1KxYrjW3nCl2N6Nq8pJW5dCtP-6wrRw4W2q-ktp5SP_t9N3bFHkNxGp7gW9gznDf729QB8W526fbt1NwHbwW1HZ_1l6JJ2vnW3KNjQB8CQTsxN1Zk5SYj6JnwW2sq8ZT8pSCpbW7x8HWT6tHq95W1RCmGv50R_dMW4zC2kF8C8zZtVP6HzT2S2Bl1W6t299h13JG_WW8d63G69jty7Wf8p5PJ204&amp;source=gmail&amp;ust=1765234931495000&amp;usg=AOvVaw1FljByZTmdmARwqeKYWSBm">expectations</a>. It matches top models on some visual tasks but stops short of the forefront (including Qwen3-Max and Kimi-K2-Thinking) on leaderboards like <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWv3qgz0W7lCdLW6lZ3n6N3NVbK2YMLqrN4MghrhM6BmvN25gsC7y2GhVW2TFbZf7JhzRSW20CNmM3tDmYmW627qr_6bcPV2W589knv777CylW5T6NgV3lZ39qW6qLS2M74ggm4W5t9nL06FpC7-W3PdDPv6z537rW4GLDnq1dlJFPW3BGR6X7dwwsxW2WYlfK8GLMXlW8FJYkp2k7n9lW5rd9h25qFwXCW6qzK_f4xfNjCN4lxHJ5Q6ff3W4Y5H-c6dCBT4W27Yhtg5yDyNFW40l2CG2-JGnbW3jYrdS8-2NcsW8q2ZcR8sTSgvW2xsTDB2DHyMtf2lkgVK04" rel="noopener" style="color:#237b94" target="_blank" data-saferedirecturl="https://www.google.com/url?q=https://info.deeplearning.ai/e3t/Ctc/LX%2B113/cJhC404/VWzf3Z3BYCghW5D8LZm5R-T8CW31NlPp5GFvTVMZjDWv3qgz0W7lCdLW6lZ3n6N3NVbK2YMLqrN4MghrhM6BmvN25gsC7y2GhVW2TFbZf7JhzRSW20CNmM3tDmYmW627qr_6bcPV2W589knv777CylW5T6NgV3lZ39qW6qLS2M74ggm4W5t9nL06FpC7-W3PdDPv6z537rW4GLDnq1dlJFPW3BGR6X7dwwsxW2WYlfK8GLMXlW8FJYkp2k7n9lW5rd9h25qFwXCW6qzK_f4xfNjCN4lxHJ5Q6ff3W4Y5H-c6dCBT4W27Yhtg5yDyNFW40l2CG2-JGnbW3jYrdS8-2NcsW8q2ZcR8sTSgvW2xsTDB2DHyMtf2lkgVK04&amp;source=gmail&amp;ust=1765234931495000&amp;usg=AOvVaw1_AZ9ySP_mjD4qNX0Fs25l">LM Arena</a>. Pretraining on text, images, video, and audio together is a relatively fresh approach that could simplify current systems that piece together different encoders and decoders for different media types.</p>
<p style="line-height:150%">&nbsp;</p>
<p style="line-height:150%"><span style="font-weight:bold">We’re thinking:</span> Ernie-5.0 may outperform Gemini 2.5 and GPT-5, but Google and OpenAI have already moved on to Gemini 3 and GPT-5.1!</p>
<p style="line-height:150%">&nbsp;</p></div>
