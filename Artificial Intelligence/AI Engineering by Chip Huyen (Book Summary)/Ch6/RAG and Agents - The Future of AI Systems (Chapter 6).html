<head>
    <script crossorigin="anonymous" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        src="https://code.jquery.com/jquery-3.2.1.min.js"></script>

    <!-- Google AdSense Using Machine Learning Code -->
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
        (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-3071098372371409",
            enable_page_level_ads: true
        });
    </script>

    <script>
        $(document).ready(function () {
            $.ajax({
                url: "https://raw.githubusercontent.com/ashishjain1547/bookSummariesAndReviews/main/links_to_book_clubs.json",
                success: function (result) {
                    let grouplink = JSON.parse(result)['current book club'];
                    $("#customWhatsAppGroupLinkWrapper").html(
                        `
                        <h2 class="custom_link_h2"><a href="${grouplink}" target="_blank"> 
                            <span>Join us on:</span>
                            <span class="customLink"><i class="fa fa-whatsapp"></i> Whatsapp </span>
                            </a>
                        </h2>
                        `
                    );
                }
            });
        });
    </script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <style>
        pre {
            white-space: pre-wrap;
            white-space: -moz-pre-wrap;
            white-space: -pre-wrap;
            white-space: -o-pre-wrap;
            word-wrap: break-word;
        }

        .customLink {
            background-color: #4CAF50;
            border: none;
            color: white !important;
            padding: 8px 13px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 14px;
            margin: 4px 2px;
            cursor: pointer;
        }

        .customLink:hover {
            text-decoration: none;
        }

        div.code-block-decoration.footer {
            display: none;
        }

        button.export-sheets-button-wrapper {
            display: none;
        }
    </style>

    <style>
        .custom_link_h2 a {
            color: black;
            text-decoration: none;
            text-align: center;
        }

        .custom_link_h2 a:hover {
            color: black;
        }

        .custom_link_h2 a:active {
            color: black;
        }

        .custom_link_h2 span {
            translate: 0px -5px;
            display: inline-block;
        }

        .custom_link_h2 img {
            width: 100px;
            padding: 0px;
            border: none;
            box-shadow: none;
        }

        .customul {
            list-style: none;
        }

        [aria-hidden='true'] {
            display: none;
        }
    </style>

    <style>
        pre {
            white-space: pre-wrap;
            white-space: -moz-pre-wrap;
            white-space: -pre-wrap;
            white-space: -o-pre-wrap;
            word-wrap: break-word;
        }

        .dot {
            height: 12px;
            width: 12px;
            background-color: #bbb;
            border-radius: 50%;
            display: inline-block;
        }

        .arrow {
            border: solid black;
            border-width: 0 3px 3px 0;
            display: inline-block;
            padding: 3px;
        }

        .right {
            transform: rotate(-45deg);
            -webkit-transform: rotate(-45deg);
        }

        .left {
            transform: rotate(135deg);
            -webkit-transform: rotate(135deg);
        }

        .up {
            transform: rotate(-135deg);
            -webkit-transform: rotate(-135deg);
        }

        .down {
            transform: rotate(45deg);
            -webkit-transform: rotate(45deg);
        }
    </style>

    <style>
        span.relative.inline-flex.items-center button {
            display: none;
        }

        div.bg-token-bg-elevated-secondary.text-token-text-secondary.flex button {
            display: none;
        }
    </style>
</head>

<a class="customLink" href="https://github.com/ashishjain1547/agentic_ai_books/blob/main/1_Chip%20Huyen%20-%20AI%20Engineering_%20Building%20Applications%20with%20Foundation%20Models-O'Reilly%20Media%20(2025).pdf" target="_blank">Download Book</a>
<br><br>
<div id="customWhatsAppGroupLinkWrapper"></div>
<a class="customLink" href="https://survival8.blogspot.com/2025/09/the-art-and-science-of-prompt.html" target="_blank">&lt;&lt;&lt; Previous Chapter</a>
<a class="customLink" href="" target="_blank">Next Chapter &gt;&gt;&gt;</a>
<br><br>

<div class="separator" style="clear: both;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEigCuANDr8rihCNvkpsxyFUOemO9pcK6MJAaHe9AaR7V1m766NznPyvEWLWtLLfnk8ZRI4NjQkHLnhO9ljovbMsHqpg8IaKAnJ1F4nBc3jxkAzc7p3Prue1meNsPkXMBe19-p_Kmq23Hz4oPFB6x3qYWqMSb6ieGviU8Jcl24a3T1Z9EHfRs4neLXlbnN6m/s686/Screenshot%20from%202025-06-26%2009-45-44.png" style="display: block; padding: 1em 0; text-align: center; "><img alt="" border="0" height="600" data-original-height="686" data-original-width="546" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEigCuANDr8rihCNvkpsxyFUOemO9pcK6MJAaHe9AaR7V1m766NznPyvEWLWtLLfnk8ZRI4NjQkHLnhO9ljovbMsHqpg8IaKAnJ1F4nBc3jxkAzc7p3Prue1meNsPkXMBe19-p_Kmq23Hz4oPFB6x3qYWqMSb6ieGviU8Jcl24a3T1Z9EHfRs4neLXlbnN6m/s600/Screenshot%20from%202025-06-26%2009-45-44.png"/></a></div>

<div class="_main_5jn6z_1 z-10 markdown prose dark:prose-invert contain-inline-size focus:outline-hidden bg-transparent ProseMirror" contenteditable="false" style="" translate="no"><h2><span>Introduction</span></h2><p><span>Large Language Models (LLMs) have transformed the way we interact with machines. Yet, while these models are powerful, they are also limited by two constraints: </span><span><strong>instructions</strong></span><span> and </span><span><strong>context</strong></span><span>. Instructions tell the model </span><span><em>what to do</em></span><span>, but context provides the </span><span><em>knowledge needed</em></span><span> to do it. Without relevant context, models are prone to mistakes and hallucinations. This is where two critical patterns come into play: </span><span><strong>Retrieval-Augmented Generation (RAG)</strong></span><span> and </span><span><strong>Agents</strong></span><span>.</span></p><p><span>RAG enhances models by retrieving relevant external knowledge, while Agents empower models to interact with tools and environments to accomplish more complex tasks. Together, these paradigms represent the next frontier of AI applications.</span></p><p><span>In this blog post, we will take a deep dive into both approaches—how they work, their architectures, the algorithms involved, optimization strategies, and their transformative potential.</span></p><div contenteditable="false"><hr></div><h2><span>Part 1: Retrieval-Augmented Generation (RAG)</span></h2><h3><span>What is RAG?</span></h3><p><span>Retrieval-Augmented Generation is a technique that enriches model outputs by retrieving the most relevant information from external data sources—be it a document database, conversation history, or the web. Rather than relying solely on the model’s training data or its limited context window, RAG dynamically builds query-specific context.</span></p><p><span>For example, if asked </span><span><em>“Can Acme’s fancy-printer-A300 print 100 pages per second?”</em></span><span>, a generic LLM might hallucinate. But with RAG, the model first retrieves the printer’s specification sheet and then generates an informed answer.</span></p><p><span>This retrieval-before-generation workflow ensures:</span></p><ul data-spread="false"><li><p><span>Reduced hallucinations</span></p></li><li><p><span>More detailed responses</span></p></li><li><p><span>Efficient use of context length</span></p></li></ul><h3><span>RAG Architecture</span></h3><p><span>A RAG system typically consists of two components:</span></p><ol data-spread="false" start="1"><li><p><span><strong>Retriever</strong></span><span> – Finds relevant information from external memory sources.</span></p></li><li><p><span><strong>Generator</strong></span><span> – Produces an output using the retrieved information.</span></p></li></ol><p><span>In practice:</span></p><ul data-spread="false"><li><p><span>Documents are pre-processed (often split into smaller </span><span><em>chunks</em></span><span>).</span></p></li><li><p><span>A retrieval algorithm finds the most relevant chunks.</span></p></li><li><p><span>These chunks are concatenated with the user’s query to form the final prompt.</span></p></li><li><p><span>The generator (usually an LLM) produces the answer.</span></p></li></ul><p><span>This modularity allows developers to swap retrievers, use different vector databases, or fine-tune embeddings to improve performance.</span></p><h3><span>Retrieval Algorithms</span></h3><p><span>Retrieval is a century-old idea—its roots go back to information retrieval systems in the 1920s. Modern RAG employs two main categories:</span></p><h4><span>1. Term-Based Retrieval (Lexical Retrieval)</span></h4><ul data-spread="false"><li><p><span>Uses </span><span><strong>keywords</strong></span><span> to match documents with queries.</span></p></li><li><p><span>Classic algorithms: </span><span><strong>TF-IDF</strong></span><span>, </span><span><strong>BM25</strong></span><span>, </span><span><strong>Elasticsearch</strong></span><span>.</span></p></li><li><p><span>Advantages: fast, cheap, effective out-of-the-box.</span></p></li><li><p><span>Limitations: doesn’t capture semantic meaning. For instance, a query for </span><span><em>“transformer architecture”</em></span><span> might return documents about electrical transformers instead of neural networks.</span></p></li></ul><h4><span>2. Embedding-Based Retrieval (Semantic Retrieval)</span></h4><ul data-spread="false"><li><p><span>Represents documents and queries as dense vectors (embeddings).</span></p></li><li><p><span>Relevance is measured by similarity (e.g., cosine similarity).</span></p></li><li><p><span>Requires </span><span><strong>vector databases</strong></span><span> (e.g., FAISS, Pinecone, Milvus).</span></p></li><li><p><span>Advantages: captures meaning, handles natural queries.</span></p></li><li><p><span>Limitations: slower, costlier, requires embedding generation.</span></p></li></ul><h4><span>Hybrid Retrieval</span></h4><p><span>Most production systems combine both approaches. For instance:</span></p><ul data-spread="false"><li><p><span>Step 1: Use BM25 to fetch candidate documents.</span></p></li><li><p><span>Step 2: Use embeddings to rerank and refine results.</span></p></li></ul><p><span>This ensures both speed and semantic precision.</span></p><h3><span>Vector Search Techniques</span></h3><p><span>Efficient vector search is key for large-scale RAG. Popular algorithms include:</span></p><ul data-spread="false"><li><p><span><strong>HNSW (Hierarchical Navigable Small World Graphs)</strong></span><span> – graph-based nearest neighbor search.</span></p></li><li><p><span><strong>Product Quantization (PQ)</strong></span><span> – compresses vectors for faster similarity comparisons.</span></p></li><li><p><span><strong>IVF (Inverted File Index)</strong></span><span> – clusters vectors for scalable retrieval.</span></p></li><li><p><span><strong>Annoy, FAISS, ScaNN</strong></span><span> – popular libraries for approximate nearest neighbor (ANN) search.</span></p></li></ul><h3><span>Evaluating Retrieval Quality</span></h3><p><span>Metrics for evaluating retrievers include:</span></p><ul data-spread="false"><li><p><span><strong>Context Precision</strong></span><span>: % of retrieved documents that are relevant.</span></p></li><li><p><span><strong>Context Recall</strong></span><span>: % of relevant documents that were retrieved.</span></p></li><li><p><span><strong>Ranking Metrics</strong></span><span>: NDCG, MAP, MRR.</span></p></li></ul><p><span>Ultimately, the retriever’s success should be measured by </span><span><strong>the quality of final generated answers</strong></span><span>.</span></p><h3><span>Optimizing Retrieval</span></h3><p><span>Several strategies enhance retrieval effectiveness:</span></p><ol data-spread="false" start="1"><li><p><span><strong>Chunking Strategy</strong></span><span> – Decide how to split documents (by tokens, sentences, paragraphs, or recursively).</span></p></li><li><p><span><strong>Reranking</strong></span><span> – Reorder retrieved documents based on relevance or freshness.</span></p></li><li><p><span><strong>Query Rewriting</strong></span><span> – Reformulate user queries for clarity.</span></p></li><li><p><span><strong>Contextual Retrieval</strong></span><span> – Augment chunks with metadata, titles, or summaries.</span></p></li></ol><h3><span>Beyond Text: Multimodal and Tabular RAG</span></h3><ul data-spread="false"><li><p><span><strong>Multimodal RAG</strong></span><span>: Retrieves both text and images (using models like CLIP).</span></p></li><li><p><span><strong>Tabular RAG</strong></span><span>: Converts natural queries into SQL (Text-to-SQL) for structured databases.</span></p></li></ul><p><span>These extensions broaden RAG’s applicability to enterprise analytics, ecommerce, and multimodal assistants.</span></p><div contenteditable="false"><hr></div><h2><span>Part 2: Agents</span></h2><h3><span>What Are Agents?</span></h3><p><span>In AI, an </span><span><strong>agent</strong></span><span> is anything that perceives its environment and acts upon it. Unlike RAG, which focuses on constructing better context, agents leverage </span><span><strong>tools and planning</strong></span><span> to interact with the world.</span></p><p><span>Examples of agents include:</span></p><ul data-spread="false"><li><p><span>A coding assistant that navigates a repo, edits files, and runs tests.</span></p></li><li><p><span>A customer-support bot that reads emails, queries databases, and sends responses.</span></p></li><li><p><span>A travel planner that books flights, reserves hotels, and creates itineraries.</span></p></li></ul><h3><span>Components of an Agent</span></h3><p><span>An agent consists of:</span></p><ol data-spread="false" start="1"><li><p><span><strong>Environment</strong></span><span> – The world it operates in (e.g., web, codebase, financial system).</span></p></li><li><p><span><strong>Actions/Tools</strong></span><span> – Functions it can perform (search, query, write).</span></p></li><li><p><span><strong>Planner</strong></span><span> – The reasoning engine (LLM) that decides which actions to take.</span></p></li></ol><h3><span>Tools: Extending Agent Capabilities</span></h3><p><span>Tools are the bridge between AI reasoning and real-world actions. They fall into three categories:</span></p><ol data-spread="false" start="1"><li><p><span><strong>Knowledge Augmentation</strong></span><span>: e.g., retrievers, SQL executors, web browsers.</span></p></li><li><p><span><strong>Capability Extension</strong></span><span>: e.g., calculators, code interpreters, translators.</span></p></li><li><p><span><strong>Write Actions</strong></span><span>: e.g., sending emails, executing transactions, updating databases.</span></p></li></ol><p><span>The choice of tools defines what an agent can achieve.</span></p><h3><span>Planning: The Agent’s Brain</span></h3><p><span>Complex tasks require </span><span><strong>planning</strong></span><span>—breaking goals into manageable steps. This involves:</span></p><ol data-spread="false" start="1"><li><p><span><strong>Plan Generation</strong></span><span> – Decomposing tasks into steps.</span></p></li><li><p><span><strong>Plan Validation</strong></span><span> – Ensuring steps are feasible.</span></p></li><li><p><span><strong>Execution</strong></span><span> – Performing steps using tools.</span></p></li><li><p><span><strong>Reflection</strong></span><span> – Evaluating results, correcting errors.</span></p></li></ol><p><span>This iterative loop makes agents adaptive and autonomous.</span></p><h3><span>Failures and Risks</span></h3><p><span>With power comes risk. Agents introduce new failure modes:</span></p><ul data-spread="false"><li><p><span><strong>Compound Errors</strong></span><span> – Mistakes in multi-step reasoning accumulate.</span></p></li><li><p><span><strong>Overreach</strong></span><span> – Misusing tools (e.g., sending wrong emails).</span></p></li><li><p><span><strong>Security Risks</strong></span><span> – Vulnerable to prompt injection or malicious tool manipulation.</span></p></li></ul><p><span>Thus, safety mechanisms, human oversight, and constrained tool permissions are critical.</span></p><h3><span>Evaluating Agents</span></h3><p><span>Evaluating agents is complex and multi-layered:</span></p><ul data-spread="false"><li><p><span>Task success rate</span></p></li><li><p><span>Efficiency (steps, latency, cost)</span></p></li><li><p><span>Robustness against adversarial inputs</span></p></li><li><p><span>User trust and satisfaction</span></p></li></ul><p><span>Unlike single-shot LLMs, agents need evaluation frameworks that capture their sequential reasoning and tool use.</span></p><div contenteditable="false"><hr></div><h2><span>The Convergence of RAG and Agents</span></h2><p><span>While distinct, RAG and Agents are complementary:</span></p><ul data-spread="false"><li><p><span>RAG provides </span><span><strong>better knowledge</strong></span><span>.</span></p></li><li><p><span>Agents provide </span><span><strong>better action</strong></span><span>.</span></p></li></ul><p><span>Together, they enable AI systems that are:</span></p><ul data-spread="false"><li><p><span>Knowledge-rich (RAG reduces hallucinations).</span></p></li><li><p><span>Action-oriented (Agents execute tasks).</span></p></li><li><p><span>Adaptive (feedback-driven planning).</span></p></li></ul><p><span>Future enterprise AI systems will likely embed both patterns: RAG for context construction and Agents for execution.</span></p><div contenteditable="false"><hr></div><h2><span>Conclusion</span></h2><p><span>RAG and Agents represent two of the most promising paradigms in applied AI today. RAG helps models overcome context limitations by dynamically retrieving relevant information. Agents extend models into autonomous actors that can reason, plan, and interact with the world.</span></p><p><span>As models get stronger and contexts expand, some may argue RAG will become obsolete. Yet, the need for efficient, query-specific retrieval will persist. Similarly, while agents bring new challenges—such as security, compound errors, and evaluation hurdles—their potential to automate real-world workflows is too transformative to ignore.</span></p><p><span>In short, </span><span><strong>RAG equips models with knowledge, and Agents empower them with action</strong></span><span>. Together, they pave the way for the next generation of intelligent systems.</span></p><div contenteditable="false"><hr></div></div>

<span style="opacity: 0;">Tags: Artificial Intelligence,Generative AI,Agentic AI,Technology,Book Summary,</span>