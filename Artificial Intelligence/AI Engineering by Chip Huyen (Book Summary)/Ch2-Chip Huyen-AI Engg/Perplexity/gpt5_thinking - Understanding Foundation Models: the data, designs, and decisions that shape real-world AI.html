<style>
    span.text-3xs.rounded-badge.group.min-w-4.cursor-pointer.text-center.align-middle {
        display: none;
    }

    span.katex-html { display: none; }
</style>
<div class="prose text-pretty dark:prose-invert inline leading-relaxed break-words min-w-0 [word-break:break-word] prose-strong:font-medium">

<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Why this matters</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Foundation models sit at the core of modern AI applications, yet the most consequential choices are made long before prompts are written or APIs are called: what data to learn from, which architectures to use, how large to scale, how to align with human preference, and how to sample outputs at inference time.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
A clear, high-level understanding of those decisions helps practitioners choose models more effectively, adapt them with less friction, and anticipate both capabilities and failure modes in production.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">What “foundation” really means</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">A foundation model is pre-trained at scale and later adapted for downstream tasks via post-training and application scaffolding, so application teams rarely need to train from scratch but do need to understand where model behaviors come from.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Even when training recipes are not fully disclosed, most differences trace back to three ingredients: training data, architecture and size, and post-training choices that align behavior with human preferences.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Seemingly subtle inference-time choices—especially sampling—can swing output helpfulness, consistency, and hallucination rates as much as large engineering changes, making them central to product quality.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">The data behind the model</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Models learn the distributions they see, so the composition and quality of training data set the outer bounds on what a model can do well, what it struggles with, and where it is likely to fail.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Because collecting massive, high-quality corpora is expensive, most model developers lean heavily on broad internet-scale sources like Common Crawl and filtered subsets such as C4, accepting noise to get coverage and scale.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
This strategy yields breadth but bakes in web-scale bias and unreliability; studies of C4 have shown substantial presence of low-trust outlets and “fake news,” and while teams use heuristics and filters (e.g., upvoted Reddit links), that seldom fixes root quality issues across domains and languages.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Curate for what is needed</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">“Use what exists” creates strong performance on what appears often on the public web but weak coverage where data is scarce or specialized, so targeted curation is essential when language, domain, or format needs diverge from general web text.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Teams either train from scratch on focused corpora or finetune strong general-purpose models on curated data for desired languages or domains, which is often more compute-efficient and faster to iterate.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Quality can trump volume; a well-chosen, smaller high-quality corpus can outperform large noisy datasets, as shown by results where modest models trained on high-quality coding tokens beat much larger baselines on developer benchmarks.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">The multilingual gap</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">English dominates web data, with English comprising nearly half of Common Crawl and many widely spoken languages severely under-represented, which translates directly into performance disparities across languages for general-purpose LLMs.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
When evaluated on knowledge and reasoning benchmarks such as MMLU, large models like GPT‑4 perform best in English and significantly worse for some low-resource languages, with striking gaps also observed on math problems translated across languages.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Translation pipelines are not a panacea: translation requires adequate understanding of the source language to begin with and can lose pragmatic and relational information, particularly for languages whose pronoun systems encode social roles or relationships.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Cost and latency vary by language</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Tokenization efficiency differs by language, so identical content in English can require dramatically more tokens in Burmese or Hindi, making non‑English inference both slower and more expensive when APIs charge per token and latency scales with generated tokens.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
In practice, this means product experience varies by locale: throughput and tail latency degrade, and per‑request cost rises for languages with longer tokenizations under identical prompt lengths and generation settings.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
These differences have motivated purpose-built models for specific languages—Chinese models like ChatGLM or Llama‑Chinese, as well as CroissantLLM (French), PhoGPT (Vietnamese), and Jais (Arabic)—which can close gaps on local tasks.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">The case for domain-specific models</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">General-purpose LLMs and VLMs can competently answer many everyday questions across law, science, and business because those domains appear in web-scale pretraining, but specialized tasks like drug discovery or clinical screening require data rarely found (or shareable) on the public web.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
This is why standout systems like AlphaFold, BioNeMo, and Med‑PaLM2 rely on curated biomolecular or medical data, and why similar opportunities likely exist in other fields with structured artifacts—architecture drawings, factory layouts, and process schematics.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
The practical implication: for narrow, high-stakes verticals, data curation and domain modeling are competitive advantages that general models cannot easily replicate without access to similarly specialized training signals.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Architecture choices that matter</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Transformers dominate language modeling thanks to attention, which removes the encoder/decoder bottlenecks of RNN-based seq2seq while enabling parallel input processing and fine-grained token-to-token conditioning during generation.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Seq2seq succeeds at mapping sequences to sequences but struggles with long-range dependencies and speed due to its strictly sequential processing, issues attention addresses by letting the decoder “look back” flexibly across previous tokens.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
In transformer inference, the prefill step parallelizes input encoding, then decode proceeds token-by-token with autoregression, making decode the primary latency bottleneck and motivating KV-cache and specialized scheduling optimizations.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">A quick tour of attention</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Attention computes how much the next token should depend on prior tokens via a dot‑product between a query vector and per‑token keys, applying those weights over per‑token values to produce a context-aware representation for the next step.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
If the model’s hidden dimension is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span>, then keys, values, and queries live in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="double-struck">R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">\mathbb{R}^{d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8491em;"><span style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>, typically split into multiple heads so different heads can attend to different patterns and positions using smaller per‑head subspaces, then concatenated and projected.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Given <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Q</mi><mo separator="true">,</mo><mi mathvariant="normal">K</mi><mo separator="true">,</mo><mi mathvariant="normal">V</mi></mrow><annotation encoding="application/x-tex">\mathrm{Q}, \mathrm{K}, \mathrm{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord mathrm">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathrm">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathrm" style="margin-right: 0.01389em;">V</span></span></span></span> for a head, attention is computed as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">f</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">x</mi></mrow><mtext> ⁣</mtext><mrow><mo fence="true">(</mo><mfrac><msup><mrow><mi mathvariant="normal">Q</mi><mi mathvariant="normal">K</mi></mrow><mi mathvariant="normal">⊤</mi></msup><msqrt><mi>d</mi></msqrt></mfrac><mo fence="true">)</mo></mrow><mi mathvariant="normal">V</mi></mrow><annotation encoding="application/x-tex">\mathrm{softmax}\!\left(\frac{\mathrm{QK}^{\top}}{\sqrt{d}}\right)\mathrm{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.8em; vertical-align: -0.65em;"></span><span class="mord"><span class="mord mathrm">softmax</span></span><span class="mspace" style="margin-right: -0.1667em;"></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.095em;"><span style="top: -2.5335em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9378em;"><span class="svg-align" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mtight" style="padding-left: 0.833em;"><span class="mord mathnormal mtight">d</span></span></span><span style="top: -2.8978em;"><span class="pstrut" style="height: 3em;"></span><span class="hide-tail mtight" style="min-width: 0.853em; height: 1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.1022em;"><span></span></span></span></span></span></span></span></span><span style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.4461em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">QK</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.927em;"><span style="top: -2.931em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathrm" style="margin-right: 0.01389em;">V</span></span></span></span>, with scaling stabilizing gradients and softmax turning similarities into weights, before outputs flow into an MLP block with simple nonlinearities like ReLU or GELU.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Blocks, embeddings, and context</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">A transformer stacks repeated blocks consisting of multi‑head attention and MLP modules, wrapped by input embeddings and positional encodings up front and a final unembedding layer to produce token probabilities for sampling.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Model size reflects dimensions and depth: hidden dimension, number of layers, feedforward expansion, and vocabulary size, while context length affects memory needs during inference but not parameter count.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Model families such as Llama 2 and Llama 3 demonstrate how these choices scale across 7B to 405B variants and how newer generations squeeze more capability per parameter at longer context lengths.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Beyond transformers: long-context contenders</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Researchers are exploring alternatives and hybrids that promise better long‑sequence efficiency and latency, including RNN‑inspired RWKV and state space models (SSMs) like S4, H3, and Mamba that reduce quadratic attention costs.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Mamba shows linear-time sequence modeling with competitive or superior quality at similar or smaller sizes, while Jamba interleaves transformer and Mamba layers and leverages mixture‑of‑experts to push context to 256K tokens efficiently.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Replacing transformers at scale is hard due to years of optimization and ecosystem tooling, but practical pressure from context length, memory, and latency continues to fuel rapid progress in SSMs and hybrid stacks.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">What “size” actually signals</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Parameter count is a rough proxy for representational capacity, but practical deployment depends on memory formats, sparsity, and architecture; for instance, a 7B dense model at 16‑bit precision needs at least ~14 GB just for weights at inference.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Sparsity and MoE change the picture: models like Mixtral 8×7B have tens of billions of total parameters but activate only a fraction per token, approaching the cost of a smaller dense model while retaining the capacity of a larger one across inputs.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Bigger can still underperform smaller if undertrained; tokens matter, not just parameters, and modern training counts tokens rather than examples to better reflect how much signal a model actually absorbed.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Counting tokens and compute</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Modern LLMs train on trillions of tokens, with families like Llama ramping from 1.4T to 15T tokens across generations, and open datasets like RedPajama‑v2 enumerating tens of trillions of raw tokens with uneven quality.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Training cost tracks floating point operations (FLOPs), not just device counts, and real-world utilization is often 50–70% of peak, which means budgeting by FLOPs and utilization is more realistic than budgeting by raw GPU hours.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
At prevailing H100 pricing and reasonable utilization, pretraining a GPT‑3‑scale dense model costs millions, underscoring why post‑training and careful model selection are so attractive for most application teams.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Scaling laws and compute‑optimal training</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Given a fixed compute budget, there’s an optimal trade between model size and tokens: the Chinchilla rule of thumb says training tokens should be about 20× parameter count, and both should scale together to stay compute‑optimal.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
The practical lesson is to plan scale by budget rather than by aspiration—choose parameter count and dataset size together rather than maxing one and starving the other, then expect newer training methods to increase quality at the same scale over time.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Because inference cost affects adoption, some teams prefer slightly smaller, faster models even if test‑set accuracy is suboptimal, and researchers have proposed ways to factor inference demand into scaling choices, not just training loss.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Diminishing returns and extrapolation</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">As accuracy rises, each extra point gets more expensive; cuts in cross‑entropy that look small on paper can translate into big downstream quality jumps, but they generally require substantial data and compute increases to achieve.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Since retraining giant models many times is infeasible, teams study hyperparameters on small models and transfer them to larger ones—a fragile but improving practice known as scaling extrapolation or hyperparameter transfer.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Emergent abilities complicate this transfer because behaviors that only appear at scale may be invisible at small sizes, so extrapolations need skepticism and redundancy in evaluation.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Bottlenecks: data and electricity</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Training data growth is outpacing fresh human-generated content online, prompting concerns about exhausting public web data and cascading effects as models start training on model-generated text and translations.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Access to proprietary, high-quality data—books, contracts, medical records, scientific corpora—will increasingly differentiate model performance, which explains high-profile licensing deals and tightening web scraping terms by major platforms.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Electricity is the less-discussed but harder constraint: data centers may reach 4–20% of global power draw by 2030, implying growth limits that are well below a few more orders of magnitude of scaling without significant energy breakthroughs.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Post‑training: from raw capability to usable behavior</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Pretraining with self‑supervision makes models good at next‑token prediction and knowledge capture but not necessarily conversational, safe, or aligned with practical user expectations for helpfulness and guardrails.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Post‑training typically uses two steps: supervised finetuning (SFT) on high‑quality instruction data to teach conversational formats, followed by preference finetuning to optimize for human‑preferred responses across ambiguous or sensitive contexts.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
While methods differ—RLHF, DPO, and RLAIF among them—the goal is the same: make outputs that people prefer more often, with SFT unlocking capability already latent in the pretrained model and preference steps shaping the voice and boundaries.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">The craft of SFT data</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">SFT uses demonstration pairs of (prompt, response) across task types like QA, summarization, and step‑wise guidance, and quality of labelers matters because many prompts require reasoning and judgment, not just lookup.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
High‑quality SFT is expensive to produce and curate at scale, which has led to volunteer efforts and heuristic mining of web dialogues, but these sources can introduce demographic skew or format bias that later surfaces in model behavior.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Some teams explore purely synthetic SFT data to reduce cost and expand coverage, but careful quality control is still required, and synthetic data is discussed more fully in data‑centric chapters.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Preference finetuning: RLHF, DPO, verifiers</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">RLHF trains a reward model from comparison data—pairs of responses ranked by preference—and then optimizes the SFT model to produce outputs that the reward model scores highly, often via PPO or related RL techniques.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
DPO offers a simpler optimization route by learning from direct preference pairs without training a separate reward model, and some large model families have switched to reduce complexity while retaining alignment benefits.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
In production, some teams skip RL and instead sample N outputs at inference and pick the best via a reward model or verifier, a “best‑of‑N” strategy that often yields large gains with simpler infrastructure.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Why preference is hard</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Even with careful design, preference learning encodes contentious trade‑offs: what is “helpful,” “harmless,” or “honest” varies by culture, domain, and risk tolerance, and comparison labels can show significant inter‑annotator variability.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Systems may also behave asymmetrically across languages or topics, producing different refusal rates or being more permissive to misinformation depending on the language, which complicates global deployments.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Because post‑training consumes a small fraction of total compute, it is a cost‑effective lever for real product gains, but its subjectivity requires continuous evaluation and red‑teaming—not just one‑time tuning.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Sampling: the most underrated performance lever</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Every generated token is sampled from a probability distribution over the vocabulary, which makes outputs probabilistic and explains both creativity and inconsistency in behavior across runs with the same prompt.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Greedy decoding—always picking the highest probability token—tends to produce safe but dull text, while stochastic sampling can increase diversity at the cost of coherence or determinism, so selecting the right strategy is task‑dependent.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
A practical debugging habit is to inspect log probabilities for tokens or sequences; low or erratic probabilities can indicate poor conditioning, malformed prompts, or miscalibrated temperature or nucleus settings.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Temperature, top‑k, top‑p</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Temperature rescales logits before softmax, with lower temperatures sharpening the distribution (more predictable) and higher temperatures flattening it (more diverse), typically bounded within a reasonable range like 0–2 for stability.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Top‑k limits sampling to the k most probable tokens before softmax, reducing compute and narrowing choices, while top‑p (nucleus) takes the smallest set whose cumulative probability exceeds p, adapting the candidate set to context.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Min‑p variations impose a floor on token probability to enter the candidate set, and stop conditions—token limits or explicit stop sequences—help bound cost and latency while avoiding truncated or malformed outputs.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Test‑time compute: electing the best output</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Generating multiple candidates per prompt—then choosing by average log probability, a verifier score, or application heuristics—often yields outsized gains compared to single-sample decoding, albeit at nearly linear cost in the number of samples.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Verifiers can rival large scale-ups; for math, a verifier lifted solution rates comparable to a 30× parameter increase, and across tasks, best‑of‑N with a competent selector is one of the most efficient ways to “buy” quality at inference time.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Returns do saturate in some studies, and very large N risks adversarial candidates that fool verifiers, so practical systems keep N modest and combine selection with domain constraints like syntax checks or unit tests where applicable.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Hallucination, inevitability, and hygiene</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Because sampling is probabilistic and pretraining is indirect, hallucinations are a structural risk, and both self‑supervision limits and supervision mismatches can contribute to confident but incorrect generations.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Detection is nontrivial—even for humans—so robust evaluation pipelines, retrieval augmentation where appropriate, and structured output validation are better mitigations than expecting a single decoding trick to eliminate the issue.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Later chapters in the source material explore measurement strategies and mitigations in depth, but at a product level, assume hallucinations are irreducible noise and build feedback and gating paths accordingly.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">How to apply these ideas today</h2>
<ul class="marker:text-quiet list-disc">
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Pick models by data fit, not just leaderboards, especially for non‑English or specialized domains where pretraining coverage dictates outcome quality as much as parameter count does.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Right‑size the stack by compute budget using scaling law heuristics; if training or finetuning, scale tokens with parameters and plan for inference cost from the start, not as an afterthought.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Invest early in post‑training data quality and evaluation; small, high‑quality SFT sets and clear preference criteria usually beat large, noisy sets without a tight evaluation loop.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Treat sampling as a first‑class control: tune temperature and nucleus settings per task, and add best‑of‑N plus verifier selection for high‑value actions where added latency and cost are justified.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Expect constraints to bite: watch for language tokenization overhead, regional behavior differences, and power and data limits that will shape both availability of models and their economics.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
</li>
</ul>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">The big picture</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Foundation models are defined as much by their data and design constraints as by their capabilities, and understanding those constraints helps engineering teams turn black-box magic into predictable systems work.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
Three numbers frame scale—parameters, tokens, and training FLOPs—while three levers dominate usability—SFT, preference finetuning, and sampling—and getting each roughly right is the difference between a demo and a dependable product.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
As architectures evolve and scaling hits real‑world limits in data and power, the competitive edge will come from better data curation, sharper post‑training, and smarter inference strategies rather than from parameter counts alone.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Appendix: a few formulas that matter</h2>
<ul class="marker:text-quiet list-disc">
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Softmax turns logits into probabilities at step <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span>: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>p</mi><mi>i</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><mfrac><msup><mi>e</mi><msubsup><mi>x</mi><mi>i</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msubsup></msup><mrow><msub><mo>∑</mo><mi>j</mi></msub><msup><mi>e</mi><msubsup><mi>x</mi><mi>j</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msubsup></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">p_{i}^{(t)}=\frac{e^{x_{i}^{(t)}}}{\sum_{j}e^{x_{j}^{(t)}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.3217em; vertical-align: -0.2769em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.6298em; vertical-align: -1.2326em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3972em;"><span style="top: -2.19em;"><span class="pstrut" style="height: 3.1004em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1496em;"><span style="top: -2.1786em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.05724em;">j</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.4603em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right: 0.1952em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 1.572em;"><span style="top: -3.572em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.9606em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3448em;"><span style="top: -2.2393em; margin-left: 0em; margin-right: 0.1em;"><span class="pstrut" style="height: 2.75em;"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.05724em;">j</span></span></span><span style="top: -3.3448em; margin-right: 0.1em;"><span class="pstrut" style="height: 2.75em;"></span><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.7052em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top: -3.3304em;"><span class="pstrut" style="height: 3.1004em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.4944em;"><span class="pstrut" style="height: 3.1004em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 1.4331em;"><span style="top: -3.4331em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.9606em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3448em;"><span style="top: -2.2393em; margin-left: 0em; margin-right: 0.1em;"><span class="pstrut" style="height: 2.75em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top: -3.3448em; margin-right: 0.1em;"><span class="pstrut" style="height: 2.75em;"></span><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.5107em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 1.2326em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> are logits from the unembedding layer.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Temperature rescales logits before softmax: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mfrac><mi>x</mi><mi>T</mi></mfrac></mrow><annotation encoding="application/x-tex">x'=\frac{x}{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7519em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.0404em; vertical-align: -0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6954em;"><span style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.13889em;">T</span></span></span></span><span style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>, with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mtext> ⁣</mtext><mo>↓</mo></mrow><annotation encoding="application/x-tex">T\!\downarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.13889em;">T</span><span class="mspace" style="margin-right: -0.1667em;"></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">↓</span></span></span></span> making outputs more deterministic and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mtext> ⁣</mtext><mo>↑</mo></mrow><annotation encoding="application/x-tex">T\!\uparrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.13889em;">T</span><span class="mspace" style="margin-right: -0.1667em;"></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">↑</span></span></span></span> making them more diverse.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Sequence log probability is additive: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi mathvariant="bold">y</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∑</mo><mi>t</mi></msub><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>t</mi></msub><mo>∣</mo><msub><mi>y</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log p(\mathbf{y})=\sum_{t}\log p(y_{t}\mid y_{&lt;t},x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop">lo<span style="margin-right: 0.01389em;">g</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathbf" style="margin-right: 0.01597em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.0497em; vertical-align: -0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1308em;"><span style="top: -2.4003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop">lo<span style="margin-right: 0.01389em;">g</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.1774em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span>, enabling average logprob selection for best‑of‑N decoding without length bias.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p>
</li>
</ul>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Closing thought</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Working productively with foundation models means accepting their probabilistic nature, then engineering systems that corral randomness into reliability using data curation, alignment, and inference strategy, rather than wishing for determinism that training and sampling do not provide.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span><br>
The rest of the source material dives into evaluation precisely because systematic measurement is what turns these ideas from principles into operating procedures for dependable AI applications at scale.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch2-1_Chip-Huyen-AI-Engineering_-Building-Applications-with-Foundation-Models-O-Reilly-Media-202.pdf</span></span></span></span></p></div>