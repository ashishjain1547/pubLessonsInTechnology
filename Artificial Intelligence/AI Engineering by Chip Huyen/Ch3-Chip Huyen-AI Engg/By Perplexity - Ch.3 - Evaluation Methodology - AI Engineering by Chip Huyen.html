<style>
    span.text-3xs.rounded-badge.group.min-w-4.cursor-pointer.text-center.align-middle {
        display: none;
    }

    span.katex-html { display: none; }
</style>

<div class="prose text-pretty dark:prose-invert inline leading-relaxed break-words min-w-0 [word-break:break-word] prose-strong:font-medium">
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Why AI Evaluation Suddenly Matters</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">As AI systems move from demos to real-world workflows, the stakes of getting their behavior right have never been higher, because the more AI is deployed, the more opportunities exist for costly or even catastrophic failure in production.  Recent incidents—from chatbots generating false legal citations to customer service bots making confidently wrong promises—underline a simple truth: without robust evaluation, the risks can eclipse the benefits.  Across teams building applications with foundation models, evaluation has quickly emerged as the hardest part to operationalize, often consuming the majority of the development effort on production-grade systems.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">This blog post distills a practical methodology for evaluating open-ended AI systems, drawing from the chapter’s structure and augmenting it with concrete patterns and pitfalls observed in the field.  It focuses on three pillars: demystifying core language-model metrics, making exact evaluation work for open-ended outputs, and using AI itself as a judge—plus how to rank models via comparative evaluation when “best” depends on user preference.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">What Makes Foundation Models Harder To Evaluate</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Evaluating powerful, open-ended models is qualitatively different from evaluating traditional ML systems because correctness isn’t always a single label and because the space of valid outputs is huge.  First, as models grow more capable, auditing their responses can demand expert-level knowledge or time-intensive reasoning, which raises the bar for trustworthy judgments.  Second, open-ended tasks don’t have a compact set of ground truths—there are many acceptable answers for a single prompt—so classic label-based metrics don’t apply cleanly.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Third, many production models are black boxes, limiting visibility into architecture, training data, and procedures that would otherwise inform risk analysis, strengths, and weaknesses.  Meanwhile, conventional benchmarks saturate quickly as models catch up, forcing a constant churn in public leaderboards without necessarily delivering application-relevant signals.  Finally, evaluation now encompasses not only task performance but also discovering emergent capabilities and boundaries—what models can do beyond their training task—and this broadens the scope and complexity of evaluation in practice.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">The Field Is Booming—But Tooling Still Lags</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">The good news is research attention has exploded, with evaluation papers and open repositories growing rapidly over the last two years.  The less-good news is that investment in evaluation trails behind the rest of the AI engineering pipeline, leaving teams with fragmented tooling and ad hoc workflows that don’t scale to enterprise reliability.  In industry surveys, many teams still “eyeball” results or rely on vibe checks, which slows iteration and amplifies risk, especially for systems handling complex or safety-critical tasks.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">What follows is a pragmatic stack for teams to escape eyeballing and put evaluation on firm footing, even when data is open-ended and business constraints are tight.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Language Modeling Metrics, Demystified</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Even when building end-user apps, understanding a handful of language-model metrics helps anticipate downstream behavior and target fixes where they matter.  Four related metrics are the backbone: entropy, cross-entropy, perplexity, and bits-per-character/byte, all of which quantify how well a model predicts the next token given context.  Intuitively, better next-token prediction means lower uncertainty and lower perplexity, which often correlates with improved downstream performance for language-model-based systems.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<ul class="marker:text-quiet list-disc">
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Entropy captures how much information each token carries in a dataset; higher entropy means more unpredictability and more bits needed to represent the data.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Cross-entropy measures how difficult the dataset is for a model to predict; it blends the data’s entropy with the model’s divergence from the true distribution.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Bits-per-character and bits-per-byte standardize comparisons across tokenizers and encodings, making compression implications more interpretable across models.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Perplexity is the exponentiated cross-entropy and serves as a handy, comparable indicator of uncertainty when predicting the next token.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
</ul>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Perplexity tends to be lower on more structured domains (like HTML), higher when the vocabulary is larger, and lower when models are given longer context windows.  In practice, perplexity is useful beyond training monitoring: it can detect data contamination in benchmarks, drive deduplication by filtering out “too-familiar” examples, and flag unusual or low-quality inputs likely to trigger errors or hallucinations.  Caveat: post-training methods like supervised fine-tuning and RLHF can increase perplexity while improving task completion, and quantization can also perturb these scores—so treat perplexity as one signal among several.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Exact Evaluation For Open-Ended Outputs</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">When a task admits a clear, unambiguous outcome, exact evaluation is the gold standard because it produces consistent judgments independent of interpretation.  Two classes are especially useful in production: functional correctness and reference-based similarity measurements.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Functional correctness validates whether the system accomplishes the intended function, which is perfect for code generation, SQL synthesis, and end-to-end tasks with measurable objectives.  In code, execution-based metrics like pass@k mirror unit testing: the model “passes” a problem if any of k attempts satisfy all test cases, and aggregate pass@k gives a robust picture of capability.  Similarly, game bots and optimization tasks can be scored by objective outcomes like score, latency, or energy saved, turning evaluation into a clean, automated loop.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">When exact execution isn’t possible, reference-based similarity matches model outputs against one or more canonical responses.  Exact match works for short, unambiguous answers, but quickly breaks down under linguistic variation and long-form generation.  That’s where lexical and semantic similarity come in: lexical methods (e.g., BLEU, ROUGE, METEOR++) measure n-gram overlap or edit distance, while semantic methods compare embeddings to assess meaning-level proximity.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Lexical metrics are fast and familiar but can punish correct paraphrases and over-reward superficial overlap, and they rely on reference sets that are expensive to build and easy to get wrong.  Semantic similarity—via embedding-based measures like BERTScore or MoverScore—better captures meaning but depends on embedding quality, adds compute overhead, and still benefits from curated references.  In practice, many teams combine lightweight lexical screening with semantic checks for longer answers, while reserving functional tests for tasks that support them.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">A Quick Primer On Embeddings</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Embeddings turn multimodal inputs—text, images, audio—into vectors that encode meaning in a shared space, enabling semantic search, clustering, anomaly detection, and evaluation.  General-purpose models like BERT, CLIP, and Sentence Transformers produce robust representations at common sizes (hundreds to a few thousand dimensions), with some APIs exposing specialized embeddings for tasks like retrieval.  Joint embedding spaces (e.g., CLIP for text-image) allow cross-modal comparison, making them powerful not just for retrieval but also for assessing alignment between generated outputs and references or prompts.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">From an evaluation lens, embeddings are the foundation of semantic similarity and can be used to measure answer–context alignment, detect off-topic responses, or quantify drift in generated content over time.  Benchmarks like MTEB help gauge embedding quality across tasks, but the ultimate test is utility in the specific application’s retrieval, ranking, or clustering workflows.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">AI As A Judge: Turning Models Into Evaluators</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">As teams hit the limits of exact checks, many turn to AI as a judge: using one model to evaluate another model’s response on criteria like correctness, relevance, coherence, groundedness, or toxicity.  The appeal is straightforward: AI judges are fast, relatively cheap compared to humans, don’t require references, and can explain their decisions—making them ideal for rapid iteration and production guardrails.  Studies show strong correlational alignment with human judgments in many settings, and in practice, teams increasingly rely on AI judges during both offline tuning and online quality control.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">There are three common ways to prompt a judge: rate a single answer given a question, compare a candidate answer against a reference answer, or compare two generated answers and pick the better one.  The most reliable results come from clear, rubric-driven prompts with examples, discrete scoring scales (e.g., 1–5), and explicit definitions of each criterion.  Many platforms ship built-in criteria (e.g., faithfulness, relevance, coherence), but beware: names overlap while definitions, scales, and prompts vary widely across tools.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Despite the upside, AI judges have limitations that need intentional mitigation.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<ul class="marker:text-quiet list-disc">
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Inconsistency: stochasticity means the same input can yield different scores; mitigate with sampling controls, rubric examples, and versioned prompts, while remembering that consistency isn’t the same as correctness.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Criteria ambiguity: “faithfulness” or “relevance” may mean different things across tools; only compare scores from the same judge configuration and expose model+prompt for every evaluation artifact.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Cost and latency: adding judge calls can multiply API spend and response time; mitigate with weaker-but-reliable judges, spot-checking subsets, and background evaluation pipelines.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Biases: self-bias (favoring own outputs), position bias (favoring first), verbosity bias (favoring longer answers) are real; randomize order, cap length, and calibrate judges with tailored prompts.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
</ul>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">The result is a versatile evaluation layer that covers subjective qualities where exact metrics fall short—best used alongside exact checks and targeted human review.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">What Model Should Judge: Stronger, Same, Or Weaker</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">There are three deployment patterns for judges, each with trade-offs in cost, fidelity, and operational complexity.  Stronger-than-candidate judges make intuitive sense and provide high-quality feedback, but they can be too slow or expensive to run continuously, especially at scale.  Same-model self-critique is surprisingly useful for sanity checks and response refinement, even if self-bias demands careful interpretation.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Weaker judges can work when specialized for narrow criteria, turning the problem from “general reasoning” into “focused detection” with compact models.  Three specialized judge types are especially promising: reward models that score prompt–answer pairs for overall quality, reference-based judges that rate similarity or quality relative to gold answers, and preference models that predict which of two answers users would favor.  Small, criterion-specific judges can deliver dependable, low-latency signals that complement stronger general-purpose evaluators.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Comparative Evaluation: When “Better” Is A Relative Judgment</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Often the goal isn’t an absolute score but a ranking of candidates to decide which model or variant to ship next, which is where comparative evaluation shines.  Instead of scoring models independently (pointwise), comparative methods pit outputs head-to-head and compute rankings from match outcomes, mirroring how chess and esports compute player ratings.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">In practice, the system serves multiple models’ answers to the same prompt, collects a human or AI judgment identifying a winner (ties allowed), and aggregates many such matches into a leaderboard using algorithms like Bradley–Terry, Elo, or TrueSkill.  Comparative evaluation works well for subjective qualities where it’s easier to pick a winner than to rate in isolation, and it’s harder to game because there’s no static reference to overfit.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">However, comparative systems bring their own challenges.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<ul class="marker:text-quiet list-disc">
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Scalability: pairwise matches grow quadratically with the number of models; mitigate with smarter sampling that focuses on uncertain pairs and leverages transitivity when it holds.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Standardization and quality control: open leaderboards capture diverse prompts but also noise, superficial tests, and potential toxicity preferences; mitigate with evaluator training, prompt curation, and filters that focus on “hard” prompts.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">From relative to absolute: a higher win rate doesn’t automatically translate to business lift; connect comparative results to task-level metrics (e.g., resolution rate, cost, latency) before making production swaps.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
</ul>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Comparative evaluation pairs well with pointwise checks: use head-to-head to narrow candidates, then validate finalists with exact metrics and production-aligned KPIs.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Putting It All Together: A Practical Evaluation Playbook</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">To move beyond demos and into reliable systems, combine exact checks, AI judging, and comparative methods into a layered pipeline that maps to real risks and real rewards.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<ul class="marker:text-quiet list-disc">
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Start from failure modes, not metrics: map where the system can go wrong—hallucinations, irrelevance, regressions on edge cases, policy violations—and design targeted tests to surface those failures quickly and reproducibly.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Instrument for exactness wherever the task allows: execution-based tests for code and SQL, schema validation for structured output, and hard-grounded checks for retrieval-heavy flows.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Use AI judges with versioned prompts and rubrics: lock judge versions, store the exact model+prompt alongside every score, and regularly revalidate correlations with human review to ensure drift doesn’t erode trust.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Calibrate for cost and latency: prefer small specialized judges for always-on checks, schedule background audits with stronger models, and use spot-checking with statistically meaningful sampling to control spend.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Balance lexical and semantic similarity: apply lightweight lexical screens for quick regressions, then semantic similarity for true meaning alignment, especially in long-form answers or paraphrase-heavy domains.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Add comparative evaluation where preference matters: run head-to-heads to separate contenders on subjective quality, then tie back to business KPIs to estimate the likely lift from a production switch.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Treat perplexity as a health signal: track it on key corpora to spot distribution shifts, benchmark contamination, or anomalous inputs that predict poor performance or safety risks.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Close the loop with human-in-the-loop: even modest expert spot-checks can catch systemic judge mistakes, disambiguate criteria, and sharpen rubrics, especially for safety and domain-intensive tasks.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
</ul>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">This layered approach avoids binary thinking—no single metric or judge will cover everything—and instead builds confidence from converging signals tuned to the application’s real-world stakes.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Prompts And Rubrics That Actually Work</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Great judges are made as much by prompts and rubrics as by models, so treat prompt engineering as part of evaluation engineering.  Clarify the task to be judged, define criteria precisely with negative examples, pick a discrete scoring scale (e.g., 1–5) with clear anchors, and include representative examples for each score so the judge learns boundaries, not just ideals.  For multi-criteria evaluation, run separate prompts per criterion—such as faithfulness, relevance, coherence—so scores remain interpretable and independently improvable over time.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">When doing pairwise comparisons, randomize answer order to minimize position bias and cap answer length to dampen verbosity bias, while explicitly instructing judges not to conflate verbosity with quality.  Always log the judge configuration, including sampling parameters, so results are reproducible and regressions are attributable to either model changes or judge drift.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Where Human Judgment Still Rules</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Despite automation, every serious pipeline needs at least some human oversight, particularly to validate new judges, calibrate criteria, and audit surprising outliers.  The goal isn’t to replace human evaluation but to reserve it for the highest-leverage checks while AI judges and exact tests handle the long tail.  Over time, this hybrid loop improves both model and judge performance, and it keeps the system grounded in domain truth rather than drifting toward superficial or biased proxies.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">A Note On Metrics Drift And Governance</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Evaluation systems are themselves living systems, which means drift happens—models update, prompts change, and distributions shift.  Maintain versioned judges, pin prompts, and store evaluation artifacts so that weekly or monthly deltas reflect real model improvements, not silent changes in evaluators.  Treat AI judges like production features: they need owners, changelogs, and quality gates.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">When To Use Which Method</h2>
<ul class="marker:text-quiet list-disc">
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Use exact methods when the task supports execution or precise matching, especially in code, SQL, or structured outputs.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Use AI judges when criteria are subjective or multifactor—relevance, coherence, helpfulness—and combine them with exact checks for high-stakes flows.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Use comparative evaluation to rank strong contenders when “better” is a preference call, and then validate finalists with application KPIs before swapping in production.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
<li class="py-0 my-0 prose-p:pt-0 prose-p:mb-2 prose-p:my-0 [&amp;&gt;p]:pt-0 [&amp;&gt;p]:mb-2 [&amp;&gt;p]:my-0">
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Track perplexity for dataset health, contamination, and drift detection, not as a sole proxy for task performance—particularly after post-training.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
</li>
</ul>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">This toolbox is complementary, not competitive, and the strongest pipelines use multiple methods tuned to the realities of their domain.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">The Road Ahead</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">As models improve, precise scoring will get harder, not easier, and comparative methods may become the most feasible way to separate top-tier systems, just as game ratings do for elite players.  Preference models that predict human choices are especially exciting because they can reduce the cost of collecting alignment data and sharpen evaluation where subjective quality matters most.  Meanwhile, the basics endure: targeted exact checks, clear rubrics, versioned judges, and tight feedback loops with humans remain the backbone of any trustworthy evaluation practice.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p>
<h2 class="mb-2 mt-4 font-display font-semimedium text-base first:mt-0">Closing Thoughts</h2>
<p class="my-2 [&amp;+p]:mt-4 [&amp;_strong:has(+br)]:inline-block [&amp;_strong:has(+br)]:pb-2">Evaluation isn’t a dashboard—it’s a system design discipline that touches data, modeling, UX, and governance.  Start from realistic failure modes, combine exact and subjective signals, and keep judges versioned and auditable, and evaluation becomes less of a blocker and more of a product advantage.  Done well, it makes AI safer, more reliable, and more useful—exactly what’s needed for the next wave of production AI.<span class="citation inline" rel="nofollow noopener" data-state="closed" aria-label="Ch3-Chip-Huyen-AI-Engg.pdf"><span class="relative -mt-px select-none whitespace-nowrap -top-px cursor-pointer font-sans text-base text-foreground selection:bg-super/50 selection:text-foreground dark:selection:bg-super/10 dark:selection:text-super"><span class="text-3xs rounded-badge group min-w-4 cursor-pointer text-center align-middle font-mono tabular-nums py-[0.1875rem] leading-snug px-[0.3rem] [@media(hover:hover)]:hover:bg-super dark:[@media(hover:hover)]:hover:text-inverse [@media(hover:hover)]:hover:text-white border-subtlest ring-subtlest divide-subtlest bg-subtle"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-paperclip tabler-icon -mt-px inline-block align-middle opacity-80 mr-xs"><path d="M15 7l-6.5 6.5a1.5 1.5 0 0 0 3 3l6.5 -6.5a3 3 0 0 0 -6 -6l-6.5 6.5a4.5 4.5 0 0 0 9 9l6.5 -6.5"></path></svg><span class="relative -mt-px inline-block align-middle max-w-[25ch] overflow-hidden" style="mask-image: linear-gradient(to right, black 70%, transparent 100%);">Ch3-Chip-Huyen-AI-Engg.pdf</span></span></span></span></p></div>